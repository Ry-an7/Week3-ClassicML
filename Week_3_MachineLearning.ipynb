{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ry-an7/Week3-ClassicML/blob/something-went-wrong/Week_3_MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywb8NifF9XN3",
        "outputId": "02574e3b-b411-4a94-d624-1abe3bcb3e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5CvOjjrL9gw"
      },
      "source": [
        "<center><h1> Introduction to Audio Classification with Machine Learning Models </h1></center>\n",
        "\n",
        "\n",
        "\n",
        "### Purpose\n",
        "This notebook serves as an introduction to working with audio data for classification problems; it is meant as a learning resource rather than a demonstration of the state-of-the-art. The techniques mentioned in this notebook apply not only to classification problems, but to regression problems and problems dealing with other types of input data as well. I provide an introduction to a few key machine learning models and the logic in choosing their hyperparameters. These objectives are framed by the task of recognizing emotion from snippets of speech audio.\n",
        "\n",
        " Training data should be used strictly for training a model, validation data strictly for tuning a model, and test data strictly to evaluate a model once it is tuned - a model should never be tuned to perform better on test data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Classic machine learning models such as Support Vector Machines (SVM), k Nearest Neighbours (kNN), and Random Forests have distinct advantages to deep neural networks in many tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQsTfGREL9g1"
      },
      "source": [
        "<!--TABLE OF CONTENTS-->\n",
        "\n",
        "\n",
        "# Table of Contents\n",
        "  - [Intro: Speech Emotion Recognition on the RAVDESS dataset](#Intro:-Speech-Emotion-Recognition-on-the-RAVDESS-dataset)\n",
        "  - [Machine Learning Process Overview](#Machine-Learning-Process-Overview)\n",
        "  - [Feature Extraction](#Feature-Extraction)\n",
        "    - [Load the Dataset and Compute Features](#Load-the-Dataset-and-Compute-Features)\n",
        "    - [Feature Scaling](#Feature-Scaling)\n",
        "  - [Classical Machine Learning Models](#Classical-Machine-Learning-Models)\n",
        "    - [Training: The 80/20 Split and Validation](#Training:-The-80/20-Split-and-Validation)\n",
        "    - [Comparing Models](#Comparing-Models)\n",
        "    - [The Support Vector Machine Classifier](#The-Support-Vector-Machine-Classifier)\n",
        "    - [k Nearest Neighbours](#k-Nearest-Neighbours)\n",
        "    - [Random Forests](#Random-Forests)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hZUcbr4PL9g2"
      },
      "source": [
        "## Intro: Speech Emotion Recognition on the RAVDESS dataset\n",
        "In this notebook we explore the most common machine learning models, specifically those available off the shelf in scikit-learn.\n",
        "\n",
        "I'm going to use the RAVDESS dataset (Ryerson Audio-Visual Database of Emotional Speech and Song dataset), created by Steven Livingstone and Frank Russo of Ryerson University. <br>\n",
        "[Details of the RAVDESS dataset](https://smartlaboratory.org/ravdess/) <br>\n",
        "[Download the dataset used in this notebook](https://zenodo.org/record/1188976) <br> Scroll half-way down the page and find \"Audio_Speech_Actors_01-24\"<br>\n",
        "\n",
        "We're going to use the audio-only speech portion of the RAVDESS dataset, ~200MB.\n",
        "Audio is sourced from 24 actors (12 male, 12 female) repeating two sentences with\n",
        "a variety of emotions and intensity. We get 1440 speech files (24 actors * 60 recordings per actor). Each audio sample has been rated  by a human 10 times for emotional quality.\n",
        "\n",
        "## Machine Learning Process Overview\n",
        "1. Feature Engineering: Choose and define the properties which our model will use to evaluate the audio files. <br>\n",
        "2. Feature Extraction: Compute the features for each audio file and build a feature matrix representing all audio files. <br>\n",
        "3. Model exploration: Test candidate models that make sense for the properies of the dataset\n",
        "4. Training the MLP Classifier model: Choose and optimize the properties of our model on validation data - hyperparameters and architechture.  <br>\n",
        "5. Evaluate our model's performance: Evaluate our model's accuracy on validation data and score it against test data which it has never seen in training.<br>\n",
        "6. Explore options for improving our model: Is our dataset the right size? Is our model too complex or too simple? <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import soundfile\n",
        "import os\n",
        "# matplotlib complains about the behaviour of librosa.display, so we'll ignore those warnings:\n",
        "import warnings; warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "b2IL0uT19_3A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eu8VPhDmL9hC"
      },
      "source": [
        "## Feature Extraction\n",
        "We're going to take full advantage of librosa, a Python library enabling audio analysis and feature extraction.\n",
        "Librosa abstracts away all the math and most of the details of mel spectrorgams, chromagrams, and MFCC.\n",
        "Although closely related, we're going to take the Mel Spectrogram, MFCC, and chromagrams of each audio file as separate features to try\n",
        "and have bit more discriminatory power between samples. <br>\n",
        "\n",
        "Let's build our feature extraction functions to get a chromagram, a mel spectorgram, and MFC coefficients for each of our audio files. Because the chromagram, mel spectrogram and MFCCs are calculated on audio frames produced by STFT, we're going to get a matrix back from each function, so we'll take the mean of those matrices to produce a single feature array for each feature and each audio sample, i.e. 3 feature arrays per audio sample.\n",
        "\n",
        "**Chromagram**: Will produce 12 features; One for each of 12 pitch classes\n",
        "\n",
        "**Mel Spectrogram**: Will produce 128 features; We've defined the number of mel frequency bands at n_mels=128\n",
        "\n",
        "**MFCC**: Will produce 40 MFCCs; I've set the number of coefficients to return at n_mfcc=40 which I found to work well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qTe93WYTL9hD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def feature_chromagram(waveform, sample_rate):\n",
        "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
        "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
        "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate).T,axis=0)\n",
        "    return chromagram\n",
        "\n",
        "def feature_melspectrogram(waveform, sample_rate):\n",
        "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
        "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=8000).T,axis=0)\n",
        "    return melspectrogram\n",
        "\n",
        "def feature_mfcc(waveform, sample_rate):\n",
        "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    # 40 filterbanks = 40 coefficients\n",
        "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    return mfc_coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xjFXIfC2L9hD"
      },
      "source": [
        "We're going to wrap our feature extraction functions so we only have to load each audio file once. After extracting our 3 audio features as NumPy arrays representing a time series, we're going to\n",
        "stack them horizontally to create a single feature array."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_waveform(waveform):\n",
        "    # If the waveform has 2 channels (stereo), convert it to mono\n",
        "    if len(waveform.shape) > 1:\n",
        "        waveform = librosa.to_mono(waveform)\n",
        "    return waveform"
      ],
      "metadata": {
        "id": "Ybf1wfXfBwc4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xPMw9ijJL9hE"
      },
      "outputs": [],
      "source": [
        "def get_features(file):\n",
        "    # load an individual soundfile\n",
        "     with soundfile.SoundFile(file) as audio:\n",
        "        waveform = audio.read(dtype=\"float32\")\n",
        "        sample_rate = audio.samplerate\n",
        "        # make sure the file is mono channel audio\n",
        "        waveform = preprocess_waveform(waveform)\n",
        "        # compute features of soundfile\n",
        "        chromagram = feature_chromagram(waveform, sample_rate)\n",
        "        melspectrogram = feature_melspectrogram(waveform, sample_rate)\n",
        "        mfc_coefficients = feature_mfcc(waveform, sample_rate)\n",
        "\n",
        "        feature_matrix=np.array([])\n",
        "\n",
        "        # Check the shape of chromagram\n",
        "        if chromagram.ndim > 1 and chromagram.shape[1] > 1:\n",
        "            #print(f\"Returning zero vector for chromagram size: {file} (shape: {chromagram.shape})\")\n",
        "            chromagram = np.zeros((12,))  # Return a zero vector of size (12,)\n",
        "\n",
        "        # Check the shape of mel spectrogram\n",
        "        if melspectrogram.ndim > 1 and melspectrogram.shape[1] > 1:\n",
        "            #print(f\"Returning zero vector for mel spectrogram size: {file} (shape: {melspectrogram.shape})\")\n",
        "            melspectrogram = np.zeros((128,))  # Return a zero vector of size (128,)\n",
        "\n",
        "        # Check the shape of MFCC coefficients\n",
        "        if mfc_coefficients.ndim > 1 and mfc_coefficients.shape[1] > 1:\n",
        "            #print(f\"Returning zero vector for MFCC size: {file} (shape: {mfc_coefficients.shape})\")\n",
        "            mfc_coefficients = np.zeros((40,))  # Return a zero vector of size (40,)\n",
        "\n",
        "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
        "        feature_matrix = np.hstack((chromagram, melspectrogram, mfc_coefficients))\n",
        "\n",
        "        return feature_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "c-C6g6psL9hE"
      },
      "source": [
        "### Load the Dataset and Compute Features\n",
        "We have to understand the labelling of the RAVDESS dataset to find the ground truth emotion for each sample.\n",
        "Each file is labelled with 7 numbers delimited by a \"-\".\n",
        "Most of the numbers describe metadata about the audio samples such as their format (video and/or audio),\n",
        "whether the audio is a song or statement, which of two statements is being read and by which actor.\n",
        "\n",
        "The third and fourth numbers pertain to the emotional quality of each sample. The third number is in the range of 1-8 with each number representing an emotion.\n",
        "The fourth number is either 1 or 2, representing normal (1) or strong (2) emotional intensity.\n",
        "\n",
        "We're going to define a dictionary based on the third number (emotion) and assign an emotion to each number as specified by the RAVDESS dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z-Pu_fB7L9hF"
      },
      "outputs": [],
      "source": [
        "#Emotions in the RAVDESS dataset\n",
        "emotions_dict ={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pTlsUOwXL9hF"
      },
      "source": [
        "Finally, let's load our entire dataset and compute the features of each audio file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mAh2AYMpL9hF"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "def load_data():\n",
        "    X,y=[],[]\n",
        "    count = 0\n",
        "    for file in glob.glob(\"Desktop/IAT 360/Assignments/3/audio_speech_actors_01-24/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions_dict[file_name.split(\"-\")[2]]\n",
        "        features = get_features(file)\n",
        "        X.append(features)\n",
        "        y.append(emotion)\n",
        "        count += 1\n",
        "        # '\\r' + end='' results in printing over same line\n",
        "        print('\\r' + f' Processed {count}/{1440} audio samples',end=' ')\n",
        "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged Dataset"
      ],
      "metadata": {
        "id": "Up99MUBiVVMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "def load_data_merged():\n",
        "    X,y=[],[]\n",
        "    count = 0\n",
        "    for file in glob.glob(\"Desktop/IAT 360/Assignments/2/Audio_Data/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotions=emotions_dict[file_name.split(\"-\")[2]]\n",
        "        features = get_features(file)\n",
        "        X.append(features)\n",
        "        y.append(emotions)\n",
        "        count += 1\n",
        "        # '\\r' + end='' results in printing over same line\n",
        "        print('\\r' + f' Processed {count}/{1440} audio samples',end=' ')\n",
        "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "AFNGokcsVS0I"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My own Audio Files"
      ],
      "metadata": {
        "id": "CkrsM-vnXeOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "def load_data_own():\n",
        "    X,y=[],[]\n",
        "    count = 0\n",
        "    for file in glob.glob(\"Desktop/IAT 360/Assignments/3/Actor_25/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions_dict[file_name.split(\"-\")[2]]\n",
        "        feature = get_features(file)\n",
        "        X.append(features)\n",
        "        y.append(emotions)\n",
        "        count += 1\n",
        "        # '\\r' + end='' results in printing over same line\n",
        "        print('\\r' + f' Processed {count}/{1440} audio samples',end=' ')\n",
        "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "ZNRe-t7VXmiM"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3Cf8q4K5L9hG"
      },
      "source": [
        "Compute the feature matrix and read the emotion labels for the entire dataset.\n",
        "Note that our regressor (independent/explanatory variable), usually denoted X, is named 'features', and our regressand (dependent variable), usually denoted y, is named 'emotions'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XeKE591aL9hG",
        "outputId": "4132403f-0db6-450f-ca13-0eeb0b2abd52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processed 1440/1440 audio samples "
          ]
        }
      ],
      "source": [
        "features, emotions = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged Dataset"
      ],
      "metadata": {
        "id": "L-4B2WsjVYL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureMerged, emotionsMerged = load_data_merged()"
      ],
      "metadata": {
        "id": "XButSFEQVMJc",
        "outputId": "1599e7c0-7a01-486c-955c-517d03f97195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processed 1447/1440 audio samples "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Own Audio Files"
      ],
      "metadata": {
        "id": "h0bbGzwjXrzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureOwn, emotionsOwn = load_data_own()"
      ],
      "metadata": {
        "id": "VVxSJyAyXuL5",
        "outputId": "d52c7663-6ebb-409f-c738-e994c5e3ee68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r Processed 1/1440 audio samples \r Processed 2/1440 audio samples \r Processed 3/1440 audio samples \r Processed 4/1440 audio samples \r Processed 5/1440 audio samples \r Processed 6/1440 audio samples \r Processed 7/1440 audio samples \r Processed 8/1440 audio samples "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RVUa7RAuL9hG"
      },
      "source": [
        "Let's see what the features we extracted look like, **also for saving both the features matrix as well as emotions array, we need to convert them to pandas dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mzxX583yL9hG",
        "outputId": "4632182a-996e-4a49-a41a-8635c741d10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Audio samples represented: 1440\n",
            "Numerical features extracted per sample: 180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.762871  0.786686  0.769217  0.768762  0.773605  0.766615  0.770437   \n",
              "1     0.747417  0.781693  0.774763  0.755513  0.770826  0.783455  0.754270   \n",
              "2     0.767132  0.788347  0.785653  0.786579  0.777644  0.755638  0.761176   \n",
              "3     0.765556  0.760809  0.754814  0.773621  0.797597  0.785697  0.754200   \n",
              "4     0.706621  0.751378  0.765778  0.754597  0.759112  0.770332  0.755594   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1435  0.633462  0.580423  0.539717  0.541983  0.569329  0.576741  0.595737   \n",
              "1436  0.667961  0.637937  0.599195  0.591554  0.581671  0.556208  0.566106   \n",
              "1437  0.640290  0.588677  0.548105  0.532067  0.551831  0.579697  0.555725   \n",
              "1438  0.612517  0.594626  0.586922  0.566910  0.584284  0.618568  0.632370   \n",
              "1439  0.682341  0.621409  0.606023  0.590485  0.575120  0.597221  0.615633   \n",
              "\n",
              "           7         8         9    ...       170       171       172  \\\n",
              "0     0.764894  0.780340  0.761150  ...  0.457082 -1.399110 -2.926856   \n",
              "1     0.748580  0.766922  0.768814  ...  0.275460 -2.521470 -2.987673   \n",
              "2     0.752333  0.774452  0.743741  ... -0.002119 -0.909152 -3.045955   \n",
              "3     0.761343  0.742356  0.725235  ... -0.403806 -1.329651 -2.513405   \n",
              "4     0.741855  0.750050  0.755684  ...  0.206463 -2.188582 -2.835500   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1435  0.595334  0.587991  0.582093  ... -2.279652 -0.956125  1.618874   \n",
              "1436  0.563750  0.556274  0.562026  ...  1.828094  2.644069  1.914414   \n",
              "1437  0.533518  0.550872  0.563250  ... -0.276459  0.734496  0.793300   \n",
              "1438  0.574341  0.554251  0.568200  ...  1.947711  3.540176  0.957979   \n",
              "1439  0.617779  0.630261  0.629224  ...  2.187292  1.822321  0.664088   \n",
              "\n",
              "           173       174       175       176       177       178       179  \n",
              "0     0.013957 -0.490734 -0.570906  0.040399 -1.207217 -1.594982 -1.436487  \n",
              "1     0.409735 -0.484184 -1.398391  0.255203 -0.984978 -2.093061 -1.040791  \n",
              "2    -0.373294 -0.849145 -0.922105 -0.170320 -1.144423 -1.725613 -1.450561  \n",
              "3    -0.190276 -0.645949 -0.553919  0.459299 -1.580085 -1.647682 -1.509511  \n",
              "4     0.463746 -1.019167 -1.411440  0.350433 -1.519892 -1.250112 -0.613852  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1435  3.121076  3.300186  0.288353  0.033574 -0.001822 -0.012087  1.695895  \n",
              "1436  2.924835  2.725102  1.226836 -0.558418  0.307047 -0.687501  0.377813  \n",
              "1437  2.693131  1.434805  0.516675 -0.040329  1.729418 -0.209399  0.046916  \n",
              "1438  1.761636 -0.212034  0.591056 -0.749358  0.786245 -0.634603  0.220848  \n",
              "1439  1.707960  0.972008  1.337858  1.225059  0.974942  0.147023  1.183601  \n",
              "\n",
              "[1440 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762871</td>\n",
              "      <td>0.786686</td>\n",
              "      <td>0.769217</td>\n",
              "      <td>0.768762</td>\n",
              "      <td>0.773605</td>\n",
              "      <td>0.766615</td>\n",
              "      <td>0.770437</td>\n",
              "      <td>0.764894</td>\n",
              "      <td>0.780340</td>\n",
              "      <td>0.761150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457082</td>\n",
              "      <td>-1.399110</td>\n",
              "      <td>-2.926856</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.490734</td>\n",
              "      <td>-0.570906</td>\n",
              "      <td>0.040399</td>\n",
              "      <td>-1.207217</td>\n",
              "      <td>-1.594982</td>\n",
              "      <td>-1.436487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747417</td>\n",
              "      <td>0.781693</td>\n",
              "      <td>0.774763</td>\n",
              "      <td>0.755513</td>\n",
              "      <td>0.770826</td>\n",
              "      <td>0.783455</td>\n",
              "      <td>0.754270</td>\n",
              "      <td>0.748580</td>\n",
              "      <td>0.766922</td>\n",
              "      <td>0.768814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-2.521470</td>\n",
              "      <td>-2.987673</td>\n",
              "      <td>0.409735</td>\n",
              "      <td>-0.484184</td>\n",
              "      <td>-1.398391</td>\n",
              "      <td>0.255203</td>\n",
              "      <td>-0.984978</td>\n",
              "      <td>-2.093061</td>\n",
              "      <td>-1.040791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767132</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.786579</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.755638</td>\n",
              "      <td>0.761176</td>\n",
              "      <td>0.752333</td>\n",
              "      <td>0.774452</td>\n",
              "      <td>0.743741</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002119</td>\n",
              "      <td>-0.909152</td>\n",
              "      <td>-3.045955</td>\n",
              "      <td>-0.373294</td>\n",
              "      <td>-0.849145</td>\n",
              "      <td>-0.922105</td>\n",
              "      <td>-0.170320</td>\n",
              "      <td>-1.144423</td>\n",
              "      <td>-1.725613</td>\n",
              "      <td>-1.450561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765556</td>\n",
              "      <td>0.760809</td>\n",
              "      <td>0.754814</td>\n",
              "      <td>0.773621</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.785697</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.761343</td>\n",
              "      <td>0.742356</td>\n",
              "      <td>0.725235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403806</td>\n",
              "      <td>-1.329651</td>\n",
              "      <td>-2.513405</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>-0.645949</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.459299</td>\n",
              "      <td>-1.580085</td>\n",
              "      <td>-1.647682</td>\n",
              "      <td>-1.509511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706621</td>\n",
              "      <td>0.751378</td>\n",
              "      <td>0.765778</td>\n",
              "      <td>0.754597</td>\n",
              "      <td>0.759112</td>\n",
              "      <td>0.770332</td>\n",
              "      <td>0.755594</td>\n",
              "      <td>0.741855</td>\n",
              "      <td>0.750050</td>\n",
              "      <td>0.755684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206463</td>\n",
              "      <td>-2.188582</td>\n",
              "      <td>-2.835500</td>\n",
              "      <td>0.463746</td>\n",
              "      <td>-1.019167</td>\n",
              "      <td>-1.411440</td>\n",
              "      <td>0.350433</td>\n",
              "      <td>-1.519892</td>\n",
              "      <td>-1.250112</td>\n",
              "      <td>-0.613852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>0.633462</td>\n",
              "      <td>0.580423</td>\n",
              "      <td>0.539717</td>\n",
              "      <td>0.541983</td>\n",
              "      <td>0.569329</td>\n",
              "      <td>0.576741</td>\n",
              "      <td>0.595737</td>\n",
              "      <td>0.595334</td>\n",
              "      <td>0.587991</td>\n",
              "      <td>0.582093</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.279652</td>\n",
              "      <td>-0.956125</td>\n",
              "      <td>1.618874</td>\n",
              "      <td>3.121076</td>\n",
              "      <td>3.300186</td>\n",
              "      <td>0.288353</td>\n",
              "      <td>0.033574</td>\n",
              "      <td>-0.001822</td>\n",
              "      <td>-0.012087</td>\n",
              "      <td>1.695895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>0.667961</td>\n",
              "      <td>0.637937</td>\n",
              "      <td>0.599195</td>\n",
              "      <td>0.591554</td>\n",
              "      <td>0.581671</td>\n",
              "      <td>0.556208</td>\n",
              "      <td>0.566106</td>\n",
              "      <td>0.563750</td>\n",
              "      <td>0.556274</td>\n",
              "      <td>0.562026</td>\n",
              "      <td>...</td>\n",
              "      <td>1.828094</td>\n",
              "      <td>2.644069</td>\n",
              "      <td>1.914414</td>\n",
              "      <td>2.924835</td>\n",
              "      <td>2.725102</td>\n",
              "      <td>1.226836</td>\n",
              "      <td>-0.558418</td>\n",
              "      <td>0.307047</td>\n",
              "      <td>-0.687501</td>\n",
              "      <td>0.377813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>0.640290</td>\n",
              "      <td>0.588677</td>\n",
              "      <td>0.548105</td>\n",
              "      <td>0.532067</td>\n",
              "      <td>0.551831</td>\n",
              "      <td>0.579697</td>\n",
              "      <td>0.555725</td>\n",
              "      <td>0.533518</td>\n",
              "      <td>0.550872</td>\n",
              "      <td>0.563250</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.276459</td>\n",
              "      <td>0.734496</td>\n",
              "      <td>0.793300</td>\n",
              "      <td>2.693131</td>\n",
              "      <td>1.434805</td>\n",
              "      <td>0.516675</td>\n",
              "      <td>-0.040329</td>\n",
              "      <td>1.729418</td>\n",
              "      <td>-0.209399</td>\n",
              "      <td>0.046916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>0.612517</td>\n",
              "      <td>0.594626</td>\n",
              "      <td>0.586922</td>\n",
              "      <td>0.566910</td>\n",
              "      <td>0.584284</td>\n",
              "      <td>0.618568</td>\n",
              "      <td>0.632370</td>\n",
              "      <td>0.574341</td>\n",
              "      <td>0.554251</td>\n",
              "      <td>0.568200</td>\n",
              "      <td>...</td>\n",
              "      <td>1.947711</td>\n",
              "      <td>3.540176</td>\n",
              "      <td>0.957979</td>\n",
              "      <td>1.761636</td>\n",
              "      <td>-0.212034</td>\n",
              "      <td>0.591056</td>\n",
              "      <td>-0.749358</td>\n",
              "      <td>0.786245</td>\n",
              "      <td>-0.634603</td>\n",
              "      <td>0.220848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>0.682341</td>\n",
              "      <td>0.621409</td>\n",
              "      <td>0.606023</td>\n",
              "      <td>0.590485</td>\n",
              "      <td>0.575120</td>\n",
              "      <td>0.597221</td>\n",
              "      <td>0.615633</td>\n",
              "      <td>0.617779</td>\n",
              "      <td>0.630261</td>\n",
              "      <td>0.629224</td>\n",
              "      <td>...</td>\n",
              "      <td>2.187292</td>\n",
              "      <td>1.822321</td>\n",
              "      <td>0.664088</td>\n",
              "      <td>1.707960</td>\n",
              "      <td>0.972008</td>\n",
              "      <td>1.337858</td>\n",
              "      <td>1.225059</td>\n",
              "      <td>0.974942</td>\n",
              "      <td>0.147023</td>\n",
              "      <td>1.183601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "print(f'\\nAudio samples represented: {features.shape[0]}')\n",
        "print(f'Numerical features extracted per sample: {features.shape[1]}')\n",
        "features_df = pd.DataFrame(features) # make it pretty for display\n",
        "\n",
        "\n",
        "#making dataframe for emotions as well\n",
        "emotions_df = pd.DataFrame(emotions) # make it pretty for display\n",
        "\n",
        "features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged Dataset"
      ],
      "metadata": {
        "id": "9RGS0DSJn6Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\nAudio samples represented: {featureMerged.shape[0]}')\n",
        "print(f'Numerical features extracted per sample: {featureMerged.shape[1]}')\n",
        "featureMerged_df = pd.DataFrame(featureMerged) # make it pretty for display\n",
        "\n",
        "\n",
        "#making dataframe for emotions as well\n",
        "emotionsMerged_df = pd.DataFrame(emotionsMerged) # make it pretty for display\n",
        "\n",
        "featureMerged_df"
      ],
      "metadata": {
        "id": "Ej-wnE5an9se",
        "outputId": "8a54ad3b-59df-4b26-d8cf-c3a08d81ae00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Audio samples represented: 1447\n",
            "Numerical features extracted per sample: 180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.762871  0.786686  0.769217  0.768762  0.773605  0.766615  0.770437   \n",
              "1     0.747417  0.781693  0.774763  0.755513  0.770826  0.783455  0.754270   \n",
              "2     0.767132  0.788347  0.785653  0.786579  0.777644  0.755638  0.761176   \n",
              "3     0.765556  0.760809  0.754814  0.773621  0.797597  0.785697  0.754200   \n",
              "4     0.706621  0.751378  0.765778  0.754597  0.759112  0.770332  0.755594   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1442  0.998534  0.995135  0.991664  0.985371  0.979484  0.975657  0.980095   \n",
              "1443  0.998534  0.995136  0.991666  0.985374  0.979496  0.975671  0.980095   \n",
              "1444  0.998534  0.995135  0.991665  0.985371  0.979486  0.975659  0.980095   \n",
              "1445  0.998534  0.995135  0.991664  0.985371  0.979484  0.975657  0.980095   \n",
              "1446  0.998534  0.995134  0.991664  0.985370  0.979482  0.975654  0.980094   \n",
              "\n",
              "           7         8         9    ...       170       171       172  \\\n",
              "0     0.764894  0.780340  0.761150  ...  0.457082 -1.399110 -2.926856   \n",
              "1     0.748580  0.766922  0.768814  ...  0.275460 -2.521470 -2.987673   \n",
              "2     0.752333  0.774452  0.743741  ... -0.002119 -0.909152 -3.045955   \n",
              "3     0.761343  0.742356  0.725235  ... -0.403806 -1.329651 -2.513405   \n",
              "4     0.741855  0.750050  0.755684  ...  0.206463 -2.188582 -2.835500   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1442  0.986627  0.993442  0.999546  ...  0.000000  0.000000  0.000000   \n",
              "1443  0.986627  0.993442  0.999546  ...  0.000000  0.000000  0.000000   \n",
              "1444  0.986627  0.993442  0.999546  ...  0.000000  0.000000  0.000000   \n",
              "1445  0.986627  0.993442  0.999546  ...  0.000000  0.000000  0.000000   \n",
              "1446  0.986627  0.993442  0.999546  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "           173       174       175       176       177       178       179  \n",
              "0     0.013957 -0.490734 -0.570906  0.040399 -1.207217 -1.594982 -1.436487  \n",
              "1     0.409735 -0.484184 -1.398391  0.255203 -0.984978 -2.093061 -1.040791  \n",
              "2    -0.373294 -0.849145 -0.922105 -0.170320 -1.144423 -1.725613 -1.450561  \n",
              "3    -0.190276 -0.645949 -0.553919  0.459299 -1.580085 -1.647682 -1.509511  \n",
              "4     0.463746 -1.019167 -1.411440  0.350433 -1.519892 -1.250112 -0.613852  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1442  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1443  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1444  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1445  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1446  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "\n",
              "[1447 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762871</td>\n",
              "      <td>0.786686</td>\n",
              "      <td>0.769217</td>\n",
              "      <td>0.768762</td>\n",
              "      <td>0.773605</td>\n",
              "      <td>0.766615</td>\n",
              "      <td>0.770437</td>\n",
              "      <td>0.764894</td>\n",
              "      <td>0.780340</td>\n",
              "      <td>0.761150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457082</td>\n",
              "      <td>-1.399110</td>\n",
              "      <td>-2.926856</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.490734</td>\n",
              "      <td>-0.570906</td>\n",
              "      <td>0.040399</td>\n",
              "      <td>-1.207217</td>\n",
              "      <td>-1.594982</td>\n",
              "      <td>-1.436487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747417</td>\n",
              "      <td>0.781693</td>\n",
              "      <td>0.774763</td>\n",
              "      <td>0.755513</td>\n",
              "      <td>0.770826</td>\n",
              "      <td>0.783455</td>\n",
              "      <td>0.754270</td>\n",
              "      <td>0.748580</td>\n",
              "      <td>0.766922</td>\n",
              "      <td>0.768814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-2.521470</td>\n",
              "      <td>-2.987673</td>\n",
              "      <td>0.409735</td>\n",
              "      <td>-0.484184</td>\n",
              "      <td>-1.398391</td>\n",
              "      <td>0.255203</td>\n",
              "      <td>-0.984978</td>\n",
              "      <td>-2.093061</td>\n",
              "      <td>-1.040791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767132</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.786579</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.755638</td>\n",
              "      <td>0.761176</td>\n",
              "      <td>0.752333</td>\n",
              "      <td>0.774452</td>\n",
              "      <td>0.743741</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002119</td>\n",
              "      <td>-0.909152</td>\n",
              "      <td>-3.045955</td>\n",
              "      <td>-0.373294</td>\n",
              "      <td>-0.849145</td>\n",
              "      <td>-0.922105</td>\n",
              "      <td>-0.170320</td>\n",
              "      <td>-1.144423</td>\n",
              "      <td>-1.725613</td>\n",
              "      <td>-1.450561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765556</td>\n",
              "      <td>0.760809</td>\n",
              "      <td>0.754814</td>\n",
              "      <td>0.773621</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.785697</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.761343</td>\n",
              "      <td>0.742356</td>\n",
              "      <td>0.725235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403806</td>\n",
              "      <td>-1.329651</td>\n",
              "      <td>-2.513405</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>-0.645949</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.459299</td>\n",
              "      <td>-1.580085</td>\n",
              "      <td>-1.647682</td>\n",
              "      <td>-1.509511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706621</td>\n",
              "      <td>0.751378</td>\n",
              "      <td>0.765778</td>\n",
              "      <td>0.754597</td>\n",
              "      <td>0.759112</td>\n",
              "      <td>0.770332</td>\n",
              "      <td>0.755594</td>\n",
              "      <td>0.741855</td>\n",
              "      <td>0.750050</td>\n",
              "      <td>0.755684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206463</td>\n",
              "      <td>-2.188582</td>\n",
              "      <td>-2.835500</td>\n",
              "      <td>0.463746</td>\n",
              "      <td>-1.019167</td>\n",
              "      <td>-1.411440</td>\n",
              "      <td>0.350433</td>\n",
              "      <td>-1.519892</td>\n",
              "      <td>-1.250112</td>\n",
              "      <td>-0.613852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1442</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991664</td>\n",
              "      <td>0.985371</td>\n",
              "      <td>0.979484</td>\n",
              "      <td>0.975657</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1443</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995136</td>\n",
              "      <td>0.991666</td>\n",
              "      <td>0.985374</td>\n",
              "      <td>0.979496</td>\n",
              "      <td>0.975671</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1444</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991665</td>\n",
              "      <td>0.985371</td>\n",
              "      <td>0.979486</td>\n",
              "      <td>0.975659</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1445</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991664</td>\n",
              "      <td>0.985371</td>\n",
              "      <td>0.979484</td>\n",
              "      <td>0.975657</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1446</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995134</td>\n",
              "      <td>0.991664</td>\n",
              "      <td>0.985370</td>\n",
              "      <td>0.979482</td>\n",
              "      <td>0.975654</td>\n",
              "      <td>0.980094</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1447 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Own Audio Files"
      ],
      "metadata": {
        "id": "b6IWU4_An-bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\nAudio samples represented: {featureOwn.shape[0]}')\n",
        "print(f'Numerical features extracted per sample: {featureOwn.shape[1]}')\n",
        "featureOwn_df = pd.DataFrame(featureOwn) # make it pretty for display\n",
        "\n",
        "\n",
        "#making dataframe for emotions as well\n",
        "emotionsOwn_df = pd.DataFrame(emotionsOwn) # make it pretty for display\n",
        "\n",
        "featureOwn_df"
      ],
      "metadata": {
        "id": "ZvNoHHYVoAKZ",
        "outputId": "77f386c6-80d5-42f9-cb96-f798e8c12c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Audio samples represented: 8\n",
            "Numerical features extracted per sample: 1440\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must pass 2-d input. shape=(8, 1440, 180)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[99], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAudio samples represented: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatureOwn\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumerical features extracted per sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatureOwn\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m featureOwn_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureOwn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# make it pretty for display\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#making dataframe for emotions as well\u001b[39;00m\n\u001b[0;32m      7\u001b[0m emotionsOwn_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(emotionsOwn) \u001b[38;5;66;03m# make it pretty for display\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:314\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    308\u001b[0m     _copy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    309\u001b[0m         copy_on_sanitize\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, dtype))\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, copy\u001b[38;5;241m=\u001b[39m_copy)\n\u001b[1;32m--> 314\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
            "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(8, 1440, 180)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Tq083zLEL9hH"
      },
      "source": [
        "We have a matrix of dim 1435 x 180. Looks good - 1435 audio samples, one per row, with a series of\n",
        "180 numerical features for each sample.\n",
        "\n",
        "**Each of the 1435 feature arrays has 180 features composed of 12 chromagram pitch classes + 128 mel spectrogram bands + 40 MFC coefficients.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will save our features matrix and emotions array in excel file we dont have to compute them everytime we run the notebook, we can just load them from the excel file whenever required. Make sure to change the path to according to your drive."
      ],
      "metadata": {
        "id": "VF2SggHTDqbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.to_csv('Desktop/featuresRavdess.csv')\n",
        "emotions_df.to_csv('Desktop/emotionsRavdess.csv')"
      ],
      "metadata": {
        "id": "u6H8hc6gDtbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged Dataset"
      ],
      "metadata": {
        "id": "VeNGrTX9Vp3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureMerged_df.to_csv('Desktop/featuresRavdessMerged.csv')\n",
        "emotionsMerged_df.to_csv('Desktop/emotionsRavdessMerged.csv')"
      ],
      "metadata": {
        "id": "h1wFjz_tVupW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Own Audio Files"
      ],
      "metadata": {
        "id": "QNR3IzJlnrnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureOwn_df.to_csv('Desktop/featuresRavdessOwn.csv')\n",
        "emotionsOwn_df.to_csv('Desktop/emotionsRavdessOwn.csv')"
      ],
      "metadata": {
        "id": "lF-GAEbLnudj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-saved Dataset"
      ],
      "metadata": {
        "id": "VpE5m-5aEyoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once saved you only need to load them later by running the cell below, and **skip every cell above** except for the one in which we import libraries."
      ],
      "metadata": {
        "id": "hHPB7dCqEotR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features=pd.read_csv('Desktop/IAT 360/Assignments/3/featuresRavdess.csv',index_col=0)\n",
        "emotions=pd.read_csv('Desktop/IAT 360/Assignments/3/emotionsRavdess.csv',index_col=0)"
      ],
      "metadata": {
        "id": "-8nlJCESEn56"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged Dataset"
      ],
      "metadata": {
        "id": "3LGZ84ZWV-r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_Merged=pd.read_csv('Desktop/IAT 360/Assignments/3/featuresRavdessMerged.csv',index_col=0)\n",
        "emotions_Merged=pd.read_csv('Desktop/IAT 360/Assignments/3/emotionsRavdessMerged.csv',index_col=0)"
      ],
      "metadata": {
        "id": "zMskAujGWAfw"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Own Audio Files"
      ],
      "metadata": {
        "id": "lNbo6S9wFGpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_Own=pd.read_csv('Desktop/IAT 360/Assignments/3/featuresRavdessOwn.csv',index_col=0)\n",
        "emotions_Own=pd.read_csv('Desktop/IAT 360/Assignments/3/emotionsRavdessOwn.csv',index_col=0)"
      ],
      "metadata": {
        "id": "GTEyfE4EFJU9"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's see if they have been loaded correctly!"
      ],
      "metadata": {
        "id": "4x2dXjybD1NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "id": "B5Xo1SVMD0qR",
        "outputId": "37b4426d-9f7d-4043-dcd3-bf189fce3f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.762871  0.786686  0.769217  0.768762  0.773605  0.766615  0.770437   \n",
              "1  0.747417  0.781693  0.774763  0.755513  0.770826  0.783455  0.754270   \n",
              "2  0.767132  0.788347  0.785653  0.786579  0.777644  0.755638  0.761176   \n",
              "3  0.765556  0.760809  0.754814  0.773621  0.797597  0.785697  0.754200   \n",
              "4  0.706621  0.751378  0.765777  0.754598  0.759112  0.770332  0.755594   \n",
              "\n",
              "          7         8         9  ...       170       171       172       173  \\\n",
              "0  0.764894  0.780340  0.761150  ...  0.457082 -1.399110 -2.926856  0.013957   \n",
              "1  0.748580  0.766922  0.768814  ...  0.275460 -2.521470 -2.987673  0.409735   \n",
              "2  0.752333  0.774452  0.743741  ... -0.002119 -0.909152 -3.045955 -0.373294   \n",
              "3  0.761343  0.742356  0.725235  ... -0.403806 -1.329651 -2.513405 -0.190276   \n",
              "4  0.741855  0.750050  0.755684  ...  0.206463 -2.188582 -2.835501  0.463746   \n",
              "\n",
              "        174       175       176       177       178       179  \n",
              "0 -0.490734 -0.570906  0.040399 -1.207218 -1.594982 -1.436487  \n",
              "1 -0.484184 -1.398391  0.255203 -0.984978 -2.093061 -1.040791  \n",
              "2 -0.849145 -0.922105 -0.170320 -1.144422 -1.725612 -1.450561  \n",
              "3 -0.645949 -0.553919  0.459299 -1.580085 -1.647682 -1.509511  \n",
              "4 -1.019167 -1.411441  0.350433 -1.519892 -1.250112 -0.613852  \n",
              "\n",
              "[5 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762871</td>\n",
              "      <td>0.786686</td>\n",
              "      <td>0.769217</td>\n",
              "      <td>0.768762</td>\n",
              "      <td>0.773605</td>\n",
              "      <td>0.766615</td>\n",
              "      <td>0.770437</td>\n",
              "      <td>0.764894</td>\n",
              "      <td>0.780340</td>\n",
              "      <td>0.761150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457082</td>\n",
              "      <td>-1.399110</td>\n",
              "      <td>-2.926856</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.490734</td>\n",
              "      <td>-0.570906</td>\n",
              "      <td>0.040399</td>\n",
              "      <td>-1.207218</td>\n",
              "      <td>-1.594982</td>\n",
              "      <td>-1.436487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747417</td>\n",
              "      <td>0.781693</td>\n",
              "      <td>0.774763</td>\n",
              "      <td>0.755513</td>\n",
              "      <td>0.770826</td>\n",
              "      <td>0.783455</td>\n",
              "      <td>0.754270</td>\n",
              "      <td>0.748580</td>\n",
              "      <td>0.766922</td>\n",
              "      <td>0.768814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-2.521470</td>\n",
              "      <td>-2.987673</td>\n",
              "      <td>0.409735</td>\n",
              "      <td>-0.484184</td>\n",
              "      <td>-1.398391</td>\n",
              "      <td>0.255203</td>\n",
              "      <td>-0.984978</td>\n",
              "      <td>-2.093061</td>\n",
              "      <td>-1.040791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767132</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.786579</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.755638</td>\n",
              "      <td>0.761176</td>\n",
              "      <td>0.752333</td>\n",
              "      <td>0.774452</td>\n",
              "      <td>0.743741</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002119</td>\n",
              "      <td>-0.909152</td>\n",
              "      <td>-3.045955</td>\n",
              "      <td>-0.373294</td>\n",
              "      <td>-0.849145</td>\n",
              "      <td>-0.922105</td>\n",
              "      <td>-0.170320</td>\n",
              "      <td>-1.144422</td>\n",
              "      <td>-1.725612</td>\n",
              "      <td>-1.450561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765556</td>\n",
              "      <td>0.760809</td>\n",
              "      <td>0.754814</td>\n",
              "      <td>0.773621</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.785697</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.761343</td>\n",
              "      <td>0.742356</td>\n",
              "      <td>0.725235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403806</td>\n",
              "      <td>-1.329651</td>\n",
              "      <td>-2.513405</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>-0.645949</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.459299</td>\n",
              "      <td>-1.580085</td>\n",
              "      <td>-1.647682</td>\n",
              "      <td>-1.509511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706621</td>\n",
              "      <td>0.751378</td>\n",
              "      <td>0.765777</td>\n",
              "      <td>0.754598</td>\n",
              "      <td>0.759112</td>\n",
              "      <td>0.770332</td>\n",
              "      <td>0.755594</td>\n",
              "      <td>0.741855</td>\n",
              "      <td>0.750050</td>\n",
              "      <td>0.755684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206463</td>\n",
              "      <td>-2.188582</td>\n",
              "      <td>-2.835501</td>\n",
              "      <td>0.463746</td>\n",
              "      <td>-1.019167</td>\n",
              "      <td>-1.411441</td>\n",
              "      <td>0.350433</td>\n",
              "      <td>-1.519892</td>\n",
              "      <td>-1.250112</td>\n",
              "      <td>-0.613852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged Dataset"
      ],
      "metadata": {
        "id": "Yb2xQHeyWH6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_Merged.head()"
      ],
      "metadata": {
        "id": "-d55aamDWJ7V",
        "outputId": "4a1b015e-b83c-4f13-db04-66417170660a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.762871  0.786686  0.769217  0.768762  0.773605  0.766615  0.770437   \n",
              "1  0.747417  0.781693  0.774763  0.755513  0.770826  0.783455  0.754270   \n",
              "2  0.767132  0.788347  0.785653  0.786579  0.777644  0.755638  0.761176   \n",
              "3  0.765556  0.760809  0.754814  0.773621  0.797597  0.785697  0.754200   \n",
              "4  0.706621  0.751378  0.765777  0.754598  0.759112  0.770332  0.755594   \n",
              "\n",
              "          7         8         9  ...       170       171       172       173  \\\n",
              "0  0.764894  0.780340  0.761150  ...  0.457082 -1.399110 -2.926856  0.013957   \n",
              "1  0.748580  0.766922  0.768814  ...  0.275460 -2.521470 -2.987673  0.409735   \n",
              "2  0.752333  0.774452  0.743741  ... -0.002119 -0.909152 -3.045955 -0.373294   \n",
              "3  0.761343  0.742356  0.725235  ... -0.403806 -1.329651 -2.513405 -0.190276   \n",
              "4  0.741855  0.750050  0.755684  ...  0.206463 -2.188582 -2.835501  0.463746   \n",
              "\n",
              "        174       175       176       177       178       179  \n",
              "0 -0.490734 -0.570906  0.040399 -1.207218 -1.594982 -1.436487  \n",
              "1 -0.484184 -1.398391  0.255203 -0.984978 -2.093061 -1.040791  \n",
              "2 -0.849145 -0.922105 -0.170320 -1.144422 -1.725612 -1.450561  \n",
              "3 -0.645949 -0.553919  0.459299 -1.580085 -1.647682 -1.509511  \n",
              "4 -1.019167 -1.411441  0.350433 -1.519892 -1.250112 -0.613852  \n",
              "\n",
              "[5 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762871</td>\n",
              "      <td>0.786686</td>\n",
              "      <td>0.769217</td>\n",
              "      <td>0.768762</td>\n",
              "      <td>0.773605</td>\n",
              "      <td>0.766615</td>\n",
              "      <td>0.770437</td>\n",
              "      <td>0.764894</td>\n",
              "      <td>0.780340</td>\n",
              "      <td>0.761150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457082</td>\n",
              "      <td>-1.399110</td>\n",
              "      <td>-2.926856</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.490734</td>\n",
              "      <td>-0.570906</td>\n",
              "      <td>0.040399</td>\n",
              "      <td>-1.207218</td>\n",
              "      <td>-1.594982</td>\n",
              "      <td>-1.436487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747417</td>\n",
              "      <td>0.781693</td>\n",
              "      <td>0.774763</td>\n",
              "      <td>0.755513</td>\n",
              "      <td>0.770826</td>\n",
              "      <td>0.783455</td>\n",
              "      <td>0.754270</td>\n",
              "      <td>0.748580</td>\n",
              "      <td>0.766922</td>\n",
              "      <td>0.768814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-2.521470</td>\n",
              "      <td>-2.987673</td>\n",
              "      <td>0.409735</td>\n",
              "      <td>-0.484184</td>\n",
              "      <td>-1.398391</td>\n",
              "      <td>0.255203</td>\n",
              "      <td>-0.984978</td>\n",
              "      <td>-2.093061</td>\n",
              "      <td>-1.040791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767132</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.786579</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.755638</td>\n",
              "      <td>0.761176</td>\n",
              "      <td>0.752333</td>\n",
              "      <td>0.774452</td>\n",
              "      <td>0.743741</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002119</td>\n",
              "      <td>-0.909152</td>\n",
              "      <td>-3.045955</td>\n",
              "      <td>-0.373294</td>\n",
              "      <td>-0.849145</td>\n",
              "      <td>-0.922105</td>\n",
              "      <td>-0.170320</td>\n",
              "      <td>-1.144422</td>\n",
              "      <td>-1.725612</td>\n",
              "      <td>-1.450561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765556</td>\n",
              "      <td>0.760809</td>\n",
              "      <td>0.754814</td>\n",
              "      <td>0.773621</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.785697</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.761343</td>\n",
              "      <td>0.742356</td>\n",
              "      <td>0.725235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403806</td>\n",
              "      <td>-1.329651</td>\n",
              "      <td>-2.513405</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>-0.645949</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.459299</td>\n",
              "      <td>-1.580085</td>\n",
              "      <td>-1.647682</td>\n",
              "      <td>-1.509511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706621</td>\n",
              "      <td>0.751378</td>\n",
              "      <td>0.765777</td>\n",
              "      <td>0.754598</td>\n",
              "      <td>0.759112</td>\n",
              "      <td>0.770332</td>\n",
              "      <td>0.755594</td>\n",
              "      <td>0.741855</td>\n",
              "      <td>0.750050</td>\n",
              "      <td>0.755684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206463</td>\n",
              "      <td>-2.188582</td>\n",
              "      <td>-2.835501</td>\n",
              "      <td>0.463746</td>\n",
              "      <td>-1.019167</td>\n",
              "      <td>-1.411441</td>\n",
              "      <td>0.350433</td>\n",
              "      <td>-1.519892</td>\n",
              "      <td>-1.250112</td>\n",
              "      <td>-0.613852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Own Audiop Files"
      ],
      "metadata": {
        "id": "X4U1-HNKFSV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_Own.head()"
      ],
      "metadata": {
        "id": "IYo4_l8qFVqd",
        "outputId": "2dc7188b-cab0-469f-9cc4-3b0598805fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.998534  0.995135  0.991665  0.985371  0.979486  0.975660  0.980095   \n",
              "1  0.998534  0.995135  0.991664  0.985370  0.979481  0.975653  0.980094   \n",
              "2  0.998534  0.995135  0.991665  0.985372  0.979488  0.975663  0.980095   \n",
              "3  0.998534  0.995135  0.991664  0.985371  0.979484  0.975657  0.980095   \n",
              "4  0.998534  0.995136  0.991666  0.985374  0.979496  0.975671  0.980095   \n",
              "\n",
              "          7         8         9  ...  170  171  172  173  174  175  176  177  \\\n",
              "0  0.986627  0.993442  0.999546  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1  0.986627  0.993442  0.999546  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2  0.986627  0.993442  0.999546  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3  0.986627  0.993442  0.999546  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4  0.986627  0.993442  0.999546  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   178  179  \n",
              "0  0.0  0.0  \n",
              "1  0.0  0.0  \n",
              "2  0.0  0.0  \n",
              "3  0.0  0.0  \n",
              "4  0.0  0.0  \n",
              "\n",
              "[5 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991665</td>\n",
              "      <td>0.985371</td>\n",
              "      <td>0.979486</td>\n",
              "      <td>0.975660</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991664</td>\n",
              "      <td>0.985370</td>\n",
              "      <td>0.979481</td>\n",
              "      <td>0.975653</td>\n",
              "      <td>0.980094</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991665</td>\n",
              "      <td>0.985372</td>\n",
              "      <td>0.979488</td>\n",
              "      <td>0.975663</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995135</td>\n",
              "      <td>0.991664</td>\n",
              "      <td>0.985371</td>\n",
              "      <td>0.979484</td>\n",
              "      <td>0.975657</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.995136</td>\n",
              "      <td>0.991666</td>\n",
              "      <td>0.985374</td>\n",
              "      <td>0.979496</td>\n",
              "      <td>0.975671</td>\n",
              "      <td>0.980095</td>\n",
              "      <td>0.986627</td>\n",
              "      <td>0.993442</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esInVDq7L9hT"
      },
      "source": [
        "Let's see the class balance of our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "Si3OFQe7L9hU",
        "outputId": "6c0656d2-d2f9-43a2-bf54-195b9412cabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAF+CAYAAAA/atNEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSs0lEQVR4nO3dd3hTdf//8VcKbeluoexSwCJ7CyoWZCMgIJQNCkUUFQVEZBRvBBwgCKg40RsZKiJbcKFFkaUCMrSCDJkKCDerpYUC7ef3h7/k25i0NCUdhOfjunpdzees9zlJTvLKGR+LMcYIAAAAAOARvPK7AAAAAACA+xDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIPka8i7cuWK1qxZo5EjR6phw4YKDQ2Vt7e3SpUqpU6dOunzzz/Pcvr4+Hi1b99e4eHh8vPzU9WqVfXMM8/owoULWU63f/9+xcbGKiIiQr6+voqIiFBsbKwOHDjgztUDAAAAgDxnMcaY/Fp4fHy8WrduLUkqVaqUbrvtNgUEBGjXrl1KSEiQJA0aNEjvvPOOLBaL3bSvvPKKnnrqKVksFjVp0kQlS5bU+vXrdeLECVWpUkUbNmxQeHi4wzI3btyoNm3aKCUlRTVq1FDNmjWVkJCg3377TQEBAYqPj9edd96Z+ysPAAAAALkgX0Pet99+q7feekvDhg1TkyZN7IZ98skn6tu3r9LS0jRv3jz169fPNmz79u267bbb5OXlpVWrVqldu3aSpJSUFHXq1Elr1qxR165dtWTJErt5pqSk6NZbb9WxY8cUFxenSZMm2YaNHTtWkydPVrly5bRnzx75+fnl4poDAAAAQO7I15B3LQ899JBmz56tli1bKj4+3tbeo0cPLV68WA899JDee+89u2kOHz6sW265Renp6dq9e7eqVq1qG/bWW2/p8ccfV+XKlbV79255ef3f2arp6emqVq2a9u7dq3feeUePPPJI7q8gAAAAALhZ4fwuICv16tWTJB09etTWdvnyZdu1en369HGYpnz58oqOjtb69eu1fPlyxcXF2YYtX75cktSrVy+7gCdJXl5e6tmzp55//nktW7bMpZCXnp6uY8eOKSgoyOG0UgAAAABwB2OMkpKSVKZMGYc8k1GBDnn79u2TJJUuXdrWtnfvXqWkpEiSGjRo4HS6Bg0aaP369dq+fbtdu/VxVtNlHC+7jh07pnLlyrk0DQAAAADkxNGjRxUREZHp8AIb8k6cOKG5c+dKkrp27WprP3jwoCQpNDRUQUFBTqe1Bi7ruJKUlJSk06dPS5IiIyOznO7UqVNKTk5WQECA0/FSU1OVmppqe2w94/Xo0aMKDg6+5roBAAAAgKsSExNVrly5THOQVYEMeVevXtX999+v8+fPq1atWnanTiYlJUlSpgFMkgIDAyX9sxH+PV1W01qns06b2XiTJ0/WxIkTHdqDg4MJeQAAAABy1bUuESuQnaE/+uijWrNmjYoVK6YlS5bIx8cnv0uyExcXp/Pnz9v+Ml4zCAAAAAD5qcAdyRs2bJhmz56tsLAwffPNN6pcubLdcOuhyeTk5EznYe0MPeNRtYyHNDObNmMn6lkdkfP19ZWvr28WawEAAAAA+aNAHckbMWKEZs6cqdDQUH399de2u2tmVKFCBUnSuXPn7E7BzMh6ZM06rvRPyCtatKgk6ciRI1lOFx4enuXpoAAAAABQUBWYkDdq1CjNmDFDISEh+vrrrzO9A2aVKlXk7+8vSdq6davTcazt9evXt2u3PnZ1OgAAAAC4URSIkDdmzBi9/PLLCgkJ0TfffKOGDRtmOq6Pj4/uvfdeSdKCBQschh8+fFibNm2SJHXp0sVumPXxwoULlZ6ebjcsPT1dn3zyiSQpJiYm5ysDAAAAAPko30Pef/7zH02ZMkWhoaHXDHhWY8aMkcVi0Zw5c/TVV1/Z2lNSUjRw4EClpaWpa9euqlq1qt10sbGxKlOmjPbu3atx48bZDRs3bpz27t2riIgI9evXzz0rBwAAAAB5zGKsnbzlg5UrV+q+++6T9E9H5DVq1HA6Xnh4uKZNm2bX9sorr+ipp56SxWJR06ZNVaJECa1fv17Hjx9XlSpVtGHDBoWHhzvMa+PGjWrTpo1SUlJUs2ZN1axZUwkJCUpISFBAQIDi4+N15513urQeiYmJCgkJ0fnz5+lCAQAAAECuyG7uyNeQN3fuXA0YMOCa45UvX16HDh1yaI+Pj9f06dO1efNmJScnKzIyUt26dVNcXFyWHQTu379fzz//vOLj43Xq1CkVL15crVq10rPPPquoqCiX14OQBwAAACC33RAhz1MQ8gAAAADktuzmjny/Jg8AAAAA4D6EPAAAAADwIIXzuwDkjgpjPs/vEm4Yh1661y3zYZtnH9s877HN8x7bPG+5a3sjf/A6zx53vs7Z5tlzo+5bOJIHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHoSQBwAAAAAehJAHAAAAAB6EkAcAAAAAHiTfQ96ePXv0+uuvKzY2VrVq1VLhwoVlsVj0wgsvZDrNhAkTZLFYsvz7/fffM51+//79io2NVUREhHx9fRUREaHY2FgdOHAgN1YRAAAAAPJM4fwu4O2339Zrr72Wo2nr1KmjunXrOh0WEhLitH3jxo1q06aNUlJSVKNGDTVu3FgJCQmaN2+elixZovj4eN155505qgcAAAAA8lu+h7yaNWvq6aefVr169VS/fn1NmjRJH3zwQbam7dy5syZMmJDtZaWkpKhHjx5KSUlRXFycJk2aZBs2duxYTZ48WT169NCePXvk5+fn6qoAAAAAQL7L95D30EMP2T328sq9M0jnzp2rY8eOqXLlyg6ng77wwgtaunSp9u7dq/nz5+uRRx7JtToAAAAAILfk+zV5eWn58uWSpF69ejmESS8vL/Xs2VOStGzZsjyvDQAAAADcId+P5F2Pbdu2acyYMTpz5oxCQkJUr149dezYUUFBQU7H3759uySpQYMGTodb263jAQAAAMCN5oYOeatWrdKqVavs2kJCQjRz5kz169fPrj0pKUmnT5+WJEVGRjqdX7ly5SRJp06dUnJysgICAnKhagAAAADIPTfk6ZpRUVGaNGmStm/frjNnzujMmTPasGGDOnTooPPnz6t///766KOP7KZJSkqy/Z9ZeAsMDLT9n5iYmOnyU1NTlZiYaPcHAAAAAAXBDRnyHnjgAcXFxalu3boKCwtTWFiYoqOjtWrVKg0ZMkSSNHz4cF2+fDlXlj958mSFhITY/qxHAAEAAAAgv92QIS8rEyZMUKFChXTq1Cn99NNPtvaM1+klJyc7nfbChQu2/4ODgzNdRlxcnM6fP2/7O3r0qBsqBwAAAIDr53Ehr2jRoipRooQk6c8//7S1BwUFqWjRopKkI0eOOJ3WGtbCw8OzvB7P19dXwcHBdn8AAAAAUBB4XMhLS0vT+fPnJcnhLpv169eXJG3dutXptNZ263gAAAAAcKPxuJC3cuVKpaSkyGKxOHSV0KVLF0nSwoULlZ6ebjcsPT1dn3zyiSQpJiYmb4oFAAAAADe74ULekSNH9OGHH+rSpUsOw1asWKGHHnpIktS3b1+VKlXKbnhsbKzKlCmjvXv3aty4cXbDxo0bp7179yoiIsKh+wUAAAAAuFHkez9527Zt0+DBg22P//jjD0nSrFmz9Nlnn9naly9frtKlS+vMmTN64IEH9Nhjj6levXoqW7asLl68qF27dmnfvn2SpObNm+vtt992WJa/v78WLVqkNm3aaNKkSVq5cqVq1qyphIQEJSQkKCAgQIsXL5afn18urzUAAAAA5I58D3mJiYl2d8G0+vPPP+1unJKamirpnw7LR48erS1btmj//v3atm2bLl++rPDwcHXo0EF9+vRRz5495eXl/CBldHS0du7cqeeff17x8fFaunSpihcvrn79+unZZ59VVFRU7qwoAAAAAOQBl0Pe0aNHZbFYFBERIUnavHmzFixYoOrVq2vQoEEuF9CsWTMZY7I9frFixfTSSy+5vJyMKlWqpHnz5l3XPAAAAACgIHL5mrw+ffrou+++kySdOHFCrVu31ubNm/XMM8/oueeec3uBAAAAAIDscznkJSQk6Pbbb5ckLVq0SDVr1tSmTZv00Ucfae7cue6uDwAAAADgApdD3pUrV+Tr6ytJio+PV6dOnSRJVatW1fHjx91bHQAAAADAJS6HvBo1auidd97R+vXr9c0336ht27aSpGPHjqlYsWJuLxAAAAAAkH0uh7wpU6Zo1qxZatasmXr37q06depI+qcTcutpnAAAAACA/OHy3TWbNWum//3vf0pMTFRYWJitfdCgQfL393drcQAAAAAA17h8JE+SjDH6+eefNWvWLCUlJUmSfHx8CHkAAAAAkM9cPpJ3+PBhtW3bVkeOHFFqaqpat26toKAgTZkyRampqXrnnXdyo04AAAAAQDa4fCRv2LBhatCggc6ePSs/Pz9be5cuXbRmzRq3FgcAAAAAcI3LR/LWr1+vTZs2ycfHx669QoUK+uuvv9xWGAAAAADAdS4fyUtPT1daWppD+59//qmgoCC3FAUAAAAAyBmXQ16bNm306quv2h5bLBZduHBB48ePV/v27d1ZGwAAAADARS6frjl9+nTdc889ql69ui5duqQ+ffpo3759Cg8P18cff5wbNQIAAAAAssnlkBcREaGdO3dq4cKF+uWXX3ThwgUNHDhQffv2tbsRCwAAAAAg77kc8iSpcOHCuv/++91dCwAAAADgOmUr5K1cuTLbM+zUqVOOiwEAAAAAXJ9shbzOnTtna2YWi8XpnTcBAAAAAHkjWyEvPT09t+sAAAAAALiBy10oAAAAAAAKrhyFvDVr1qhDhw6KiopSVFSUOnTooPj4eHfXBgAAAABwkcsh76233lLbtm0VFBSkYcOGadiwYQoODlb79u315ptv5kaNAAAAAIBscrkLhUmTJumVV17RE088YWsbOnSooqOjNWnSJD3++ONuLRAAAAAAkH0uH8k7d+6c2rZt69Depk0bnT9/3i1FAQAAAAByxuWQ16lTJy1fvtyh/dNPP1WHDh3cUhQAAAAAIGdcPl2zevXqevHFF7V27Vo1atRIkvTjjz9q48aNGjFihGbOnGkbd+jQoe6rFAAAAABwTS6HvNmzZyssLEy7du3Srl27bO2hoaGaPXu27bHFYiHkAQAAAEAecznkHTx4MDfqAAAAAAC4AZ2hAwAAAIAHcflInjFGS5Ys0XfffaeTJ08qPT3dbviyZcvcVhwAAAAAwDUuh7wnn3xSs2bNUvPmzVWyZElZLJbcqAsAAAAAkAMuh7wPPvhAy5YtU/v27XOjHgAAAADAdXD5mryQkBDdcsstuVELAAAAAOA6uRzyJkyYoIkTJ+rixYu5UQ8AAAAA4Dq4fLpmjx499PHHH6tEiRKqUKGCvL297YZv27bNbcUBAAAAAFzjcsjr37+/fv75Z91///3ceAUAAAAAChiXQ97nn3+u1atXq3HjxrlRDwAAAADgOrh8TV65cuUUHBycG7UAAAAAAK6TyyFv+vTpGjVqlA4dOpQL5QAAAAAArofLp2vef//9SklJUVRUlPz9/R1uvHLmzBm3FQcAAAAAcI3LIe/VV1/NhTIAAAAAAO6Qo7trAgAAAAAKJpdDXkaXLl3S5cuX7dq4KQsAAAAA5B+Xb7ySnJysJ554QiVKlFBAQIDCwsLs/gAAAAAA+cflkDdq1Ch9++23evvtt+Xr66v//ve/mjhxosqUKaP58+fnRo0AAAAAgGxy+XTNVatWaf78+WrWrJkGDBigJk2aqFKlSipfvrw++ugj9e3bNzfqBAAAAABkg8tH8s6cOaNbbrlF0j/X31m7TGjcuLHWrVvn3uoAAAAAAC5xOeTdcsstOnjwoCSpatWqWrRokaR/jvCFhoa6tTgAAAAAgGtcDnkDBgzQzp07JUljxozRm2++qSJFimj48OEaOXKk2wsEAAAAAGSfy9fkDR8+3PZ/q1attHv3bm3btk2VKlVS7dq13VocAAAAAMA119VPniRVqFBBFSpUcEMpAAAAAIDrle3TNX/44Qd99tlndm3z589XxYoVVaJECQ0aNEipqaluLxAAAAAAkH3ZDnnPPfecfvvtN9vjX3/9VQMHDlSrVq00ZswYrVq1SpMnT86VIgEAAAAA2ZPtkLdjxw61bNnS9njhwoW644479N577+mpp57SzJkzbXfaBAAAAADkj2yHvLNnz6pkyZK2x99//73atWtne9ywYUMdPXrUvdUBAAAAAFyS7ZBXsmRJW/94ly9f1rZt23TnnXfahiclJcnb29v9FQIAAAAAsi3bIa99+/YaM2aM1q9fr7i4OPn7+6tJkya24b/88ouioqJypUgAAAAAQPZkuwuF559/XjExMWratKkCAwM1b948+fj42Ia///77atOmTa4UCQAAAADInmyHvPDwcK1bt07nz59XYGCgChUqZDd88eLFCgwMdHuBAAAAAIDsc7kz9JCQEKftRYsWve5iAAAAAADXJ9vX5AEAAAAACr58D3l79uzR66+/rtjYWNWqVUuFCxeWxWLRCy+8cM1p4+Pj1b59e4WHh8vPz09Vq1bVM888owsXLmQ53f79+xUbG6uIiAj5+voqIiJCsbGxOnDggLtWCwAAAADyRb6HvLfffltDhw7VvHnzlJCQoLS0tGxN98orr6h169b66quvVKNGDXXs2FHnz5/XpEmT1KBBA/3vf/9zOt3GjRtVp04dzZs3T6GhoerSpYtCQ0M1b9481a5dWz/++KM7Vw8AAAAA8lS2Ql79+vV19uxZSdJzzz2nlJQUtxVQs2ZNPf300/roo4+0e/duPfDAA9ecZvv27RoxYoQKFSqkzz//XN9//70WLVqkP/74Qy1bttSePXv06KOPOkyXkpKiHj16KCUlRXFxcUpISNDChQuVkJCguLg4JScnq0ePHrp48aLb1g8AAAAA8lK2Qt7u3buVnJwsSZo4ceI1T4d0xUMPPaSXX35Zffr0UdWqVeXlde2SJk+eLGOMBgwYoHbt2tna/f39NXv2bHl5eWnp0qX6/fff7aabO3eujh07psqVKzucDvrCCy+ocuXKOnr0qObPn++elQMAAACAPJatu2vWrVtXAwYMUOPGjWWM0bRp0zLtLuHZZ591a4H/dvnyZX3++eeSpD59+jgML1++vKKjo7V+/XotX75ccXFxtmHLly+XJPXq1cshTHp5ealnz556/vnntWzZMj3yyCO5uBYAAAAAkDuyFfLmzp2r8ePH67PPPpPFYtGXX36pwoUdJ7VYLLke8vbu3Ws7XbRBgwZOx2nQoIHWr1+v7du327VbH2c1XcbxAAAAAOBGk62QV6VKFS1cuFDSP0e81qxZoxIlSuRqYZk5ePCgJCk0NFRBQUFOxylXrpzduJKUlJSk06dPS5IiIyOznO7UqVNKTk5WQECA0/FSU1OVmppqe5yYmOjiWgAAAABA7nD57prp6en5FvCkf8KapEwDmCTbqaQZw5d1uqymzXgKalbBbfLkyQoJCbH9WcMhAAAAAOS3HHWh8Mcff2jIkCFq1aqVWrVqpaFDh+qPP/5wd20FVlxcnM6fP2/7O3r0aH6XBAAAAACSchDyVq9ererVq2vz5s2qXbu2ateurZ9++kk1atTQN998kxs12rGeomm926cz1rt/BgcHO0yX1bQZ7xqacdp/8/X1VXBwsN0fAAAAABQE2bomL6MxY8Zo+PDheumllxzaR48erdatW7utOGcqVKggSTp37pySkpKcXpdnPbJmHVf6J+QVLVpUZ86c0ZEjR1SnTp1MpwsPD8/ydFAAAAAAKKhcPpK3e/duDRw40KH9wQcf1K5du9xSVFaqVKkif39/SdLWrVudjmNtr1+/vl279bGr0wEAAADAjcLlkFe8eHHt2LHDoX3Hjh15ckMWHx8f3XvvvZKkBQsWOAw/fPiwNm3aJEnq0qWL3TDr44ULFyo9Pd1uWHp6uj755BNJUkxMjNvrBgAAAIC84PLpmg8//LAGDRqkAwcO6K677pIkbdy4UVOmTNFTTz3l9gKdGTNmjJYsWaI5c+aoa9euatu2rSQpJSVFAwcOVFpamrp27aqqVavaTRcbG6sXX3xRe/fu1bhx4/Tiiy/aho0bN0579+5VRESE+vXrlyfrAQAACp4KYz7P7xJuCIdeuje/SwCQCZdD3rhx4xQUFKTp06crLi5OklSmTBlNmDBBQ4cOdbmAbdu2afDgwbbH1rt0zpo1S5999pmtffny5SpdurSkf06nnD59up566im1b99eTZs2VYkSJbR+/XodP35cVapU0TvvvOOwLH9/fy1atEht2rTRpEmTtHLlStWsWVMJCQlKSEhQQECAFi9eLD8/P5fXAwAAAAAKApdDnsVi0fDhwzV8+HBb33OZdUqeHYmJifrpp58c2v/880/9+eeftscZOx+XpOHDh6tWrVqaPn26Nm/erOTkZEVGRiouLk5xcXGZ1hQdHa2dO3fq+eefV3x8vJYuXarixYurX79+evbZZxUVFZXjdQEAAACA/OZyyMvoesKdVbNmzWSMydG01n76XFWpUiXNmzcvR8sEAAAAgIIsR52hAwAAAAAKJkIeAAAAAHgQQh4AAAAAeBCXQt6VK1fUsmVL7du3L7fqAQAAAABcB5dCnre3t3755ZfcqgUAAAAAcJ1cPl3z/vvv1+zZs3OjFgAAAADAdXK5C4WrV6/q/fffV3x8vG677TYFBATYDZ8xY4bbigMAAAAAuMblkJeQkKD69etLkvbu3Ws3zGKxuKcqAAAAAECOuBzyvvvuu9yoAwAAAADgBjnuQmH//v1avXq1Ll68KEkyxritKAAAAABAzrgc8k6fPq2WLVuqcuXKat++vY4fPy5JGjhwoEaMGOH2AgEAAAAA2edyyBs+fLi8vb115MgR+fv729p79uypr776yq3FAQAAAABc4/I1eV9//bVWr16tiIgIu/Zbb71Vhw8fdlthAAAAAADXuXwkLzk52e4IntWZM2fk6+vrlqIAAAAAADnjcshr0qSJ5s+fb3tssViUnp6uqVOnqnnz5m4tDgAAAADgGpdP15w6dapatmyprVu36vLlyxo1apR+++03nTlzRhs3bsyNGgEAAAAA2eTykbyaNWtq7969aty4se677z4lJycrJiZG27dvV1RUVG7UCAAAAADIJpeP5ElSSEiInnnmGXfXAgAAAAC4TjkKeWfPntXs2bO1e/duSVL16tU1YMAAFS1a1K3FAQAAAABc4/LpmuvWrVOFChU0c+ZMnT17VmfPntXMmTNVsWJFrVu3LjdqBAAAAABkk8tH8h5//HH17NlTb7/9tgoVKiRJSktL0+DBg/X444/r119/dXuRAAAAAIDscflI3v79+zVixAhbwJOkQoUK6amnntL+/fvdWhwAAAAAwDUuh7z69evbrsXLaPfu3apTp45bigIAAAAA5Ey2Ttf85ZdfbP8PHTpUw4YN0/79+3XnnXdKkn788Ue9+eabeumll3KnSgAAAABAtmQr5NWtW1cWi0XGGFvbqFGjHMbr06ePevbs6b7qAAAAAAAuyVbIO3jwYG7XAQAAAABwg2yFvPLly+d2HQAAAAAAN8hRZ+jHjh3Thg0bdPLkSaWnp9sNGzp0qFsKAwAAAAC4zuWQN3fuXD3yyCPy8fFRsWLFZLFYbMMsFgshDwAAAADykcshb9y4cXr22WcVFxcnLy+Xe2AAAAAAAOQil1NaSkqKevXqRcADAAAAgALI5aQ2cOBALV68ODdqAQAAAABcJ5dP15w8ebI6dOigr776SrVq1ZK3t7fd8BkzZritOAAAAACAa3IU8lavXq0qVapIksONVwAAAAAA+cflkDd9+nS9//77io2NzYVyAAAAAADXw+Vr8nx9fRUdHZ0btQAAAAAArpPLIW/YsGF6/fXXc6MWAAAAAMB1cvl0zc2bN+vbb7/VZ599pho1ajjceGXZsmVuKw4AAAAA4BqXQ15oaKhiYmJyoxYAAAAAwHVyOeTNmTMnN+oAAAAAALiBy9fkAQAAAAAKLpeP5FWsWDHL/vAOHDhwXQUBAAAAAHLO5ZD35JNP2j2+cuWKtm/frq+++kojR450V10AAAAAgBxwOeQNGzbMafubb76prVu3XndBAAAAAICcc9s1ee3atdPSpUvdNTsAAAAAQA64LeQtWbJERYsWddfsAAAAAAA54PLpmvXq1bO78YoxRidOnNCpU6f01ltvubU4AAAAAIBrXA55nTt3tnvs5eWl4sWLq1mzZqpataq76gIAAAAA5IDLIW/8+PG5UQcAAAAAwA3oDB0AAAAAPEi2j+R5eXll2Qm6JFksFl29evW6iwIAAAAA5Ey2Q97y5cszHfbDDz9o5syZSk9Pd0tRAAAAAICcyXbIu++++xza9uzZozFjxmjVqlXq27evnnvuObcWBwAAAABwTY6uyTt27Jgefvhh1apVS1evXtWOHTs0b948lS9f3t31AQAAAABc4FLIO3/+vEaPHq1KlSrpt99+05o1a7Rq1SrVrFkzt+oDAAAAALgg26drTp06VVOmTFGpUqX08ccfOz19EwAAAACQv7Id8saMGSM/Pz9VqlRJ8+bN07x585yOt2zZMrcVBwAAAABwTbZDXr9+/a7ZhQIAAAAAIH9lO+TNnTs3F8sAAAAAALhDju6uWRDExsbKYrFk+Xfp0iWn0/7888/q3r27SpYsqSJFiqhixYoaMmSITp48mcdrAQAAAADule0jeQVVdHS0KlWq5HRYoUKFHNqWLFmi3r176+rVq2rYsKEqVqyorVu36o033tDixYu1YcOGTOcHAAAAAAXdDR/yHnroIcXGxmZr3GPHjql///66evWqZs2apUGDBkmS0tLSFBsbqw8//FB9+vTRTz/9xPWHAAAAAG5IN+zpmjnx6quvKiUlRa1atbIFPOmfI35vv/22QkJCtGXLFn399df5WCUAAAAA5NxNFfKWL18uSerTp4/DsMDAQHXq1EkS3UAAAAAAuHHd8Kdrfvfdd/r111+VlJSkYsWK6fbbb1f79u3l6+trN15SUpL2798vSWrQoIHTeTVo0EAffPCBtm/fnut1AwAAAEBuuOFD3vz58x3aSpcurffff19t27a1tR06dMj2f2RkpNN5lStXTpJ08ODBLJeZmpqq1NRU2+PExERXSgYAAACAXHPDnq5Zp04dvfbaa0pISFBiYqL+/vtvff3117rrrrt0/PhxderUSWvXrrWNn5SUZPs/ICDA6TwDAwMlXTu0TZ48WSEhIbY/azgEAAAAgPx2w4a84cOHa+jQoapRo4aCgoJUokQJtW7dWhs2bNB9992nK1eu6Mknn8yVZcfFxen8+fO2v6NHj+bKcgAAAADAVTdsyMuMxWLRxIkTJUk7d+60BbCgoCDbOMnJyU6nvXDhgiQpODg4y2X4+voqODjY7g8AAAAACgKPC3mSVK1aNdv/f/75pySpfPnytrYjR444nc4aCCtUqJB7xQEAAABALvLIkHf69Gnb/9YjeMHBwapUqZIkaevWrU6ns7bXr18/lysEAAAAgNzhkSFv4cKFkv4JdlWqVLG1d+nSRZK0YMECh2kuXLigVatWSZJiYmLyoEoAAAAAcL8bMuTt2LFDK1eu1NWrV+3a09PTNXv2bI0dO1aSNHToUHl7e9uGP/nkk/L391d8fLzee+89W3taWpoGDx6sc+fOqWHDhmrTpk3erAgAAAAAuNkN2U/eoUOH1KVLF4WFhal+/foqWbKkzp07p4SEBNv1dr1799b48ePtpitTpozmzp2r3r17a9CgQZo9e7YqVKigLVu26MCBAypZsqQWLFggi8WSH6sFAAAAANfthjySV6dOHT355JOqUaOGfv/9dy1btkxr1qyRJHXr1k2ff/65FixYoMKFHTNs9+7d9dNPPykmJkYHDhzQ8uXLlZaWpscff1w7d+60XbcHAAAAADeiG/JIXsWKFfXKK6/kePrbbrtNS5cudWNFAAAAAFAw3JBH8gAAAAAAzhHyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIMQ8gAAAADAgxDyAAAAAMCDEPIAAAAAwIPctCFv8eLFatasmcLCwhQQEKA6depo6tSpunLlSn6XBgAAAAA5dlOGvCeffFI9evTQxo0bdfvtt6tt27Y6cuSIRo8erRYtWujixYv5XSIAAAAA5MhNF/JWrFih1157TYGBgfrpp5+0evVqLV26VPv27VOtWrW0YcMGjRs3Lr/LBAAAAIAcuelC3qRJkyRJY8aMUf369W3t4eHheuuttyRJb7zxhs6fP58v9QEAAADA9bipQt5ff/2lLVu2SJL69OnjMLxx48YqV66cUlNT9cUXX+R1eQAAAABw3W6qkLd9+3ZJUtGiRVWxYkWn4zRo0MBuXAAAAAC4kRTO7wLy0sGDByVJkZGRmY5Trlw5u3GdSU1NVWpqqu2x9dTOxMREd5TpFumpKfldwg3DXc8b2zz72OZ5j22e99jmecudn8Fs8+xhm+c9tnneK0jf76X/q8cYk+V4N1XIS0pKkiQFBARkOk5gYKCkrJ/QyZMna+LEiQ7t1oCIG0vIq/ldwc2HbZ732OZ5j22et9jeeY9tnvfY5nmvoG7zpKQkhYSEZDr8pgp57hIXF6ennnrK9jg9PV1nzpxRsWLFZLFY8rGygisxMVHlypXT0aNHFRwcnN/l3BTY5nmPbZ732OZ5j22e99jmeY9tnvfY5tljjFFSUpLKlCmT5Xg3VcgLCgqSJCUnJ2c6zoULFyQpyxeXr6+vfH197dpCQ0Ovv8CbQHBwMG/cPMY2z3ts87zHNs97bPO8xzbPe2zzvMc2v7asjuBZ3VQ3XqlQoYIk6ejRo5mOYx1mHRcAAAAAbiQ3VcirV6+eJOn06dOZ3lhl69atkmTXhx4AAAAA3ChuqpAXERGhhg0bSpIWLFjgMHzDhg06evSofH191b59+7wuz6P5+vpq/PjxDqe5IvewzfMe2zzvsc3zHts877HN8x7bPO+xzd3LYq51/00Ps2LFCnXp0kWBgYH6/vvvbUfsTp8+rebNm+vXX3/ViBEjNG3atHyuFAAAAABcd9OFPEkaNmyYZs6cKW9vb7Vs2VIBAQFas2aNzp07p+joaH3zzTfy8/PL7zIBAAAAwGU3ZciTpEWLFunNN9/Ujh07dOXKFUVFRen+++/X8OHD5ePjk9/lAQAAAECO3LQhDwAAAAA80U114xXgZmSxWGSxWPK7jDxXoUIFWSwWHTp0yNbWrFkzWSwWrV27Nt/q8jSrVq1SkyZNFBwcbHutFdTt+9dff+mBBx5QmTJlVLhwYVksFsXGxl7XPCdMmCCLxaIJEya4pcbsulnf1ygY5s6d65b3jyeLjY2VxWLR3Llz87sUj5Ff+9vsKmj75ZuqM3QAuBlYP2Ry+0SNHTt2qGvXrkpPT1eLFi1UunRpWSwWlSpVKleXmxPGGMXExGjz5s2qXr26mjdvLm9vbzVu3Di/SwNyJK/e5wBuTIQ8ADeN+fPnKyUlRZGRkfldikdYsWKFrly5orFjx+rFF1/M73KydPjwYW3evFmRkZHauXOnChfm4w8AbiRPPPGEevXqpfDw8Pwu5YbApxyAmwbhzr2OHDkiSbr11lvzuZJrs9ZasWJFAh4A3IDCw8MJeC7gmryb1ObNmzVq1CjdfvvtKlWqlHx8fFSyZEl17NhR8fHxDuNnPP8+OTlZcXFxqlSpknx9fVWqVCn1799ff/31V6bL+/TTT9WkSRMFBQUpJCRETZs21eeff65Dhw7JYrGoQoUKduNnbE9LS9OMGTNUr149BQYGymKxKDExUcHBwSpcuLCOHj2a6XLbt28vi8Wit956K8fbKrelpKTo1VdfVePGjRUWFiZfX1+VL19eHTt21IIFC2zjHT58WFOmTFGLFi0UGRkpX19fhYaGqnHjxpo1a5bS09NdWm7Ga9a+/PJLNWvWTCEhIQoLC1OHDh3066+/2sZdsGCBGjVqpKCgIIWGhiomJkZ//PGH27ZBTu3atUvdu3dXeHi4/Pz8VLNmTU2bNk1paWlOx8/smrzU1FS9/PLLuu222xQUFCQfHx+VKlVKDRs21KhRo3TmzBmHeSUkJKhr164KDw+Xv7+/atWqpVdffVXp6elOrweUrn2+fmb1nT9/Xv/5z39Uq1YtBQQEyNfXV2XKlFF0dLSeffZZXblyRdL/Xa/w7+VZ//5dT05ZlzNnzhxJ0oABA2zLaNasmW28s2fPavz48apbt66CgoJs2+mFF15QSkqKw3yTkpL03nvvKSYmRrfeeqsCAgIUEBCgWrVq6ZlnntG5c+ec1pNxe3/66adq0aKFihYtarsexmKxqGnTppKk77//3uk2yew5syrI19csXbpUjRs3VnBwsAICAhQdHa0vvvjC6bi7du3S+PHjFR0drbJly8rHx0fFihVTq1attGjRIqfTrF271vbcpqSkaOzYsapUqZKKFCmiMmXKaODAgU73/xn341evXtXUqVNVo0YN+fn5KTw8XD169NDvv/9uN80ff/yhQoUKKSwszOlrxKpGjRqyWCyZruf1yPg+dWXbStLVq1f13//+V82aNVPRokXl6+urihUr6rHHHnP6WXWta9ucfUZm932ecd5nzpzRk08+qaioKPn6+tq9T+Pj4zVkyBDVrVtX4eHh8vX1VUREhHr27KktW7Zkf8MVMPv27dODDz6oihUrytfXV4GBgSpfvrzuvfde275Lkq5cuaIPP/xQffv2VdWqVRUcHCw/Pz9VqVJFQ4cO1bFjxzJdhnW7li9fXr6+voqMjNQTTzzh9DMjt2V3fa91XVvG93tm7SkpKXr22WdVrVo1+fv7270+M75/3nvvPd12220KCAhQaGio2rdvrx9//NHpcrPaj1s/E7OqffHixWrVqpWKFSsmb29vFStWTNWrV9fDDz+sX375xekylyxZorZt26p48eLy8fFR2bJldf/992vXrl3ON7KkH374Qe3atVNoaKgCAwPVoEEDvf/++5mOn68MbkotW7Y0Xl5eplatWqZ9+/ame/fupn79+kaSkWReffVVu/HnzJljJJnOnTub2rVrm9DQUNOxY0dz3333mRIlShhJpnz58ubcuXMOy5oyZYptvnfccYfp3bu3adiwoZFkRo0aZZs2o4MHDxpJJjIy0nTq1Mn4+PiYli1bmt69e5vatWsbY4wZMmSIkWTGjh3rdB33799vLBaLCQ4ONklJSe7ZcG525MgRU716dSPJ+Pv7m9atW5tevXqZJk2amJCQELvt8vzzzxtJpmLFiqZly5amV69epmnTpsbHx8dIMjExMSY9Pd1hGdZt/2/ly5c3ksyYMWOMxWIx0dHRpkePHqZy5cpGkgkNDTX79+83I0eONIULFzYtWrQw3bp1M+XKlTOSTJkyZcyZM2dyc/Nkaf369SYgIMBIMrfccovp1auXadWqlfH29jZdu3a1rd/Bgwdt0zRt2tRIMt99952tLS0tzbRs2dJIMsHBwaZdu3amd+/eplWrVrZ5bN++3W7Za9euNX5+fkaSiYqKMr169TKtW7c2Pj4+pmfPnk6XbUzmz0VW9SUnJ5uaNWsaSaZ48eKmY8eOplevXqZZs2amVKlSRpI5e/asMcaY5cuXm/79+9uW079/f7u/U6dO5XBr27MuJyoqykgy0dHRtmVMnjzZGGPMb7/9ZnutlC5d2rRt29Z07NjRlCxZ0kgydevWddhfrF+/3raejRs3Nj179jRt2rQxxYoVM5JMpUqVzP/+9z+Heqzb+4knnjCSTIMGDUzv3r1N06ZNzbp160z//v3NPffcYySZkiVLOt0mmT1nVtbtOmfOHLv28ePHG0lm/Pjx171dXWF9jp999lnb+7dnz56mTp06RpKxWCxm2bJlDtMNHDjQSDJVq1Y199xzj+nZs6dp1KiR8fLyMpLM8OHDHab57rvvjCTTqFEjc+eddxp/f3/b50bp0qWNJFOqVCmzd+9eu+ms+/Hy5cubmJgY4+3tbVq1amV69eplbrnlFiPJBAYGmk2bNtlN17FjRyPJvPvuu07X/dtvv7W995zt865XTrdtYmKiadasmW29mjZtarp162aqVKliJJlixYqZbdu22U1j/Wzt37+/01oybkOr7L7PrfO+9957TcWKFU1YWJjp1KmT6d69u+nbt69tflFRUcbHx8fUq1fPdOrUycTExNg+lwoXLmyWLFniUNe16s5vv/76qwkODjaSTJUqVUxMTIzp3r27adSokQkMDDR16tSxjXv06FEjyYSEhJg777zTdO/e3bRv396UKVPGtj/at2+fwzJOnDhhbr31ViPJhIWFmZiYGNO5c2cTGhpqoqKiTKdOnZzuM/J7fa+1z7K+35s2beq0/Y477jANGzY0AQEBpl27dqZnz56mVatWtvGsr8vhw4cbi8ViGjdubHr37m37HCtcuLDT98+19uNZ1T5x4kTbvO+++27Tu3dv0759e1OzZk1jsVjMK6+8Yjf+lStXTI8ePYwk4+vra+666y7TvXt323vcz8/PfPnllw41Llq0yBQqVMhIMjVr1jS9e/c2jRs3NhaLxTz11FPX/IzPawWnEuSpL774whw7dsyhfdOmTSY4ONh4e3ubP//809Zu3aFLMvfcc485f/68bdiZM2dM3bp1jSQzadIku/lt27bNFCpUyBQqVMjhTb1o0SLbF4vMQp4kExERYfbs2eNQ6969e43FYjElSpQwly5dchg+YsQII8kMGTIkW9skr6WlpZkGDRoYSaZNmzbm5MmTdsMvXrxoPv/8c9vjzZs3m19//dVhPn/99Zdtx7Ro0SKH4dcKeb6+viY+Pt7WfvXqVdO9e3fbTqxYsWJmx44dtuHJycnmrrvuMpLMCy+8kKN1v14XL160BYgnn3zSXL161TZs586dJjw83Lbe1wp533//vZFk6tWrZxITEx2WtWXLFrtgkZKSYsqWLWskmREjRpi0tDTbsN9++80WYtwV8ubNm2ckmXbt2pnLly/bjZ+WlmbWrl1rUlNTXVqOu2QWfFJSUmwB8D//+Y9dfcnJyaZ3795GkhkwYIDddEePHjXx8fF229Q6Tb9+/YwkM3jwYIc6rK/lQoUKmU8//dRprZl9cfn3PG60kBcaGmp+/PFHpzVVrlzZYbq1a9eaP/74w6H9999/NxEREUaS+emnn+yGWbedNWgfPnzYNuzixYuma9euRpK588477abLuB8PDw83O3futA27evWq7Ye68uXL2+3Dv/nmGyPJ7otpRtblTZ8+PfMNdB1yum379OljJJkOHTqYv//+227YK6+8YiSZW2+91W5/lZOQ9+86M5Pxc7tly5Z2n9sZLV++3OkPdsuXLzeFCxc2xYoVMykpKU7nXVBD3oABAzL9jEpJSTHff/+97XFiYqL59NNPHfajly9fNnFxcUaSad++vcN8unXrZiSZJk2a2P1gdfr0aXPHHXfYtn1ehDxX1vd6Q54kU7t2bXP8+HGn01vH8fPzM2vWrLEbNnXqVFug/vd7JDv7cWe1X7p0yfj5+ZnAwEDz+++/O0xz6NAhs3v3bru2sWPH2gLrgQMH7IYtXrzYFCpUyISFhdl+QDXGmOPHj5ugoCAjycyYMcNumvj4eFOkSBFCHgo+607tzTfftLVZd+gBAQFOw+HChQuNJNOiRQu79gcffNBIMr1793a6LOtOMquQN3/+/Exrbd++vZFkPvjgA7v2lJQUExYWZiwWi9M3fUGwYsUKI/1zlON6jzSuXr3aSDLdu3d3GHatkDdy5EiHYdu2bbNNl/F1YLV06VIjyTRv3vy66s6pDz/80Egy5cqVcwg+xvzfF6rshLxFixYZSWbo0KHZWvb8+fNtr1lny37jjTfcGvKsH4r//lDJSn6HvLffftv2ZdeZpKQkU6JECVO4cOFsHw1OTk42hQsXNsWLF3cYZn0tP/jgg5lO76khb+bMmQ7DLl26ZEJCQowkc+TIkWzPc9asWU73CRm/3K1YscJhur///tv4+/sbSWbjxo229oz78X+fHWKt0/qDyUcffWQ3rEaNGkaSWb9+vV370aNHTeHChY2/v7/dFzB3ysm23bVrl7FYLKZMmTJOfywy5v8+r1atWmVry4uQ5+3t7TTYZ4f1B5mMPzhmp+78Zt3W/z5ymhNlypQxXl5eds/rkSNHjJeXl7FYLOa3335zmGb79u15GvJcWV93hDzrkTVnrOM8+eSTTodbf9x+8cUX7dqzsx93VvvJkydtwTM7Tp8+bfz8/EyRIkXsDmZkNHjwYCPJvP7667a2F154wemPWVbDhg0rcCGPa/JuYqdPn9b8+fM1atQoPfzww4qNjVVsbKy+//57SdKePXscpmnQoIFKly7t0F6tWjVJcrguwzqvvn37Oq0hs/aMunbtmumwYcOGSZLeeOMNu/YFCxbo7NmzatWqlapUqXLNZeSHr776SpLUp08fBQYGZmua1NRUrVq1Ss8++6weffRRDRgwQLGxsZo1a5Yk58/ZtbRv396hLeONNLIantW1CrnJen5+jx495O3t7TC8f//+2Z5X/fr1VahQIb3//vt68803dfz48SzHt76mu3fv7nTZ2XlNu6Jhw4aSpKlTp2r+/Pn5cq2Hqz7//HNJUs+ePZ0Ot17HcPXqVafX/GzatElTpkzR448/bnuNDx48WD4+Pjp16pTOnj3rdL7dunVz30rcIDp27OjQ5uvrq1tuuUWS4z5Zki5cuKDFixdr7NixGjRokG3fv3TpUkmZ70dCQ0PVqVMnh/YSJUqobdu2kpRpH4nO3pO+vr6218i/pxs6dKgkx337rFmzdPXqVfXt21ehoaFOl+UurmzbL774QsYYtWvXTkFBQU7nZ73GadOmTe4vNgv16tWz1ZyZY8eO6b333tOIESP00EMP2V4Tv/32m6Scfbbkp9tvv12S9Nhjj2n16tW6dOnSNafZuXOnZsyYoSFDhujBBx+0bYOrV68qPT1d+/fvt427bt06paenq379+qpevbrDvOrWravatWu7b4WuISfrm1MlSpRQkyZNrjleZp/D/fr1k5T5vsLV/Xjx4sVVoUIF/fLLLxoxYkSW19NJ0nfffaeLFy/arkt2xtl71VpvZp/xrnzvyCvcYuwm9d5772n48OFKTk7OdJzExESHtszuThgcHCxJDjuWP//8U5IcbqxilVm7VYkSJeTv75/p8NatW6tatWr66aef9PPPP+u2226TJL355puS/rndbkF1+PBhSVLVqlWzNf6PP/6onj172u4S6Iyz5+xanD2nGUOns+HWLzG5+UGSFevrqmLFik6Hh4WFKSQkROfPn7/mvKKiovTKK69o5MiReuKJJ/TEE0+ofPnyatSokTp06KDu3bvLx8fHYdmZvXZDQ0OzvezsaNasmUaPHq2XX35Z/fv3l8Vi0a233qro6Gjdd9996tixo7y8CtbvdQcOHJAkPfDAA3rggQeyHPfUqVO2/0+ePKmuXbtqw4YNWU6TmJiosLAwh/Zr7U88kav75FWrVmnAgAE6ffp0pvPMbD9ivTGCM9b3ovX9kVFoaGimgSyz6e6//36NGTNGy5Yt0/Hjx1W6dGldvnxZ7733nqS82be7sm2tr/nZs2dr9uzZWc4342s+L1zrfTFx4kS9+OKLths4OZOTz5b8NHLkSG3YsEHx8fFq27atvL29VadOHd19993q1auX7cczSUpOTtYDDzyg5cuXZznPjNvgWp9B1mGZ3fDD3VxZ3+uV3f1sZtsmq32FK/PPaP78+erWrZtmzJihGTNmqGjRorrjjjvUunVrPfDAA3Z35LS+V9esWXPNjsszvlev9Zxn9VrIL4S8m9DPP/+sRx55RIUKFdKUKVPUsWNHRUZGyt/fXxaLRe+++64eeeQRpx2s5vTLZGZvpGu9wfz8/K453yFDhmjw4MF64403NGfOHP3www/avn27KlSooA4dOuSo3oImJSVFnTt31t9//60BAwboscceU6VKlRQcHKxChQpp7969qlKlSo46xb3Wc1rQAkRuGDJkiHr06KGVK1dqw4YN2rBhgxYuXKiFCxdq/PjxWr9+vcMR7Kxeu9d6XWcmszukvvTSS3r00Ue1atUqbdiwQRs3btScOXM0Z84cNWzYUN99950CAgJytMzcYF2Ptm3bqmTJklmOW758edv/Dz30kDZs2KBGjRpp4sSJqlOnjsLCwmxHTMuUKaPjx49n+jq/1v7ierh699q84sr786+//lLPnj118eJFjRo1Sn379lWFChUUGBgoLy8vff3117rnnnuuq3PtnE777+n8/f318MMPa+rUqXr33Xc1fvx4LV26VH///beaNGmSJ0dJXNm21tdH3bp1VadOnSzHveOOO1ye7/XI6n2xbNkyTZgwQYGBgXrjjTfUokULlSlTRn5+frJYLBo7dqwmT558w3W47u/vr2+++UZbtmzRV199pU2bNmnTpk3aunWrZsyYocGDB9t+DI6Li9Py5ctVtWpVvfTSS2rYsKHCw8NtP+7ddddd+uGHHwr0NnBlfa/lWq85d+1n3bkfb9KkiQ4dOqTPP/9c33//vTZt2qTVq1fryy+/1Pjx47V8+XK1bNlS0v+tX6VKlRQdHZ3lfLP7I3xBRci7CS1evFjGGA0ZMkSjRo1yGL5v3z63Lats2bI6cOCADh065PSUBnfc0r1fv34aO3asFi5cqGnTptlO73nssccKdECx/kr871uIO7Nu3Tr9/fffql+/vtNb9brzObsRWE+xyOz1c+7cOZePpJUsWVIPP/ywHn74YUn/PC8PPvigfvjhB40ZM0bz5s3L1rLPnz+f6a3+vb29deXKFSUlJTk9pct6dNeZChUqaMiQIRoyZIgkacuWLbr//vu1ZcsWTZ06VRMnTszuqua6cuXK6ffff9fAgQOzfepNcnKyvvjiC3l5eemLL75wOPKTnJysEydO5EK1/7B+oUtKSnI6PKvn5kaxatUqXbx4UV26dNGUKVMchl9rP5LV/to6LCIiwmHYuXPndO7cOadH87Ka7vHHH9f06dP17rvvauzYsbZ9e0E8Q6NcuXKSpOjoaIdTTLOS3687a7cZL774ogYNGuQw/Eb/bGnYsKHtKNbVq1e1YsUK9evXT2+99Za6deum5s2b27bBJ5984vTHA2fb4FqfA9calluys7559Zo7ePCg6tat69Ce1Xv+evj5+albt262z5xTp07pP//5j9599109+OCDtvWyvlerVKniUpc4ZcuW1e+//57p85ofz/e1FNxvwMg11mt6Mv6CbnXp0iXbdRnucPfdd0uSXX9vGWXW7oqAgAANHDhQly5d0qRJk7RkyRIVKVJEAwcOvO555ybrNSwff/xxlqfNSv/3nGV2+tCHH37o3uIKOGufZ4sWLXJ6itH8+fOvexlVq1bV6NGjJUk7duywtVtf04sXL9bVq1cdpsvqNW39YrB7926HYb/88kuWfT7+W8OGDTV48GCH+iTZjnw5qy8vtGvXTpIy7XfNmfPnzystLU3BwcFOw8CHH36Yq7+kZ/XcnDhxQtu2bcu1ZeeVrPb9xphr7o/PnTunVatWObSfOnXKdo3xv/vWsvrggw8c2i5fvqxPPvkk0+kiIyPVuXNnHTt2TM8++6w2bdqkMmXKKCYmJss684P1Nb9y5UqXTmO3vu4y+7HPen2rM+54n2f1mjh58qS++eabHM+7oClcuLC6deume+65R9L/7Tez2garV6/W//73P4f2u+++WxaLRdu2bXP63O3cuTPPTtXMTGbrm9W+Tsr6NecKZ+/5jO2Z7SvcpXjx4po6daok6ciRI7ZruVu2bCkfHx+tXbtWJ0+ezPb8rN87PvroI6fD3fG9w90IeTch601S5s2bZ/dLzqVLlzR48GAdPHjQbct64okn5OXlpYULF+rTTz+1G7Zs2TK3BUrrcmbMmKHLly+rd+/eKlasmFvmnVs6deqkevXq6dixY+revbvDNTKXLl3Sl19+Ken/nrM1a9Y4XFT87rvv2r4o3Sy6deumsmXL6siRI4qLi7M7vSQhIUEvvPBCtuf17bff6osvvnAIi8YYffbZZ5LsP/y7d++u0qVL69ChQ3rmmWfslv3777/rueeey3RZrVq1kvTPNTCpqam29kOHDql///5OQ8zy5cttF/lndOXKFdsX639/ObH+Qmq9aUJeGzRokMqXL6/Fixdr9OjRTn8xPnHihO36KumfI6lhYWE6d+6cw5eDH3/8UXFxcblas/W5mTJlit2R2FOnTqlfv366cOFCri4/L1j3I0uWLLG7wVBaWpotRF3LiBEj7K6lSU1N1eOPP67k5GTdfvvtmZ7+9PzzzyshIcH2OD09XaNHj9aff/6pcuXKZXqDLevNtV566SVJ0iOPPKLChQveSUj16tVT165ddfToUcXExDj9VT85OVkfffSR/v77b1vb7bffruDgYO3atcvhdb948WLNnDkz02W6431ufU28++67unz5sq39/Pnz6t+/v9uuLc5rb731ltObxZw4cUJbt26V9H/7Tes2eP311+3G3bNnjx599FGn84+MjFSXLl2Unp6uxx57zO56vbNnz2rw4MF5enqnK+vbokULeXl5afXq1bYbiUn/fObNnDnTbd/L3n77bYebq7zyyivavHmzgoKC3PZD/OHDh/Xf//7X6XWj1h+lwsLCbNfSlixZUkOGDFFycrI6duyoX3/91WG61NRUrVy50i7ADxw4UIGBgfrhhx8c3pdr167VO++845b1cas8v58n8t3Zs2dtt6otVqyY6dy5s+nataspUaKECQoKst0GNuOtka/nNs+TJk2y3Vb2zjvvNH369DG33367kWTry+7WW2/N9vwy07lzZ9tyfv7552xPl58OHTpk6yjX39/ftGnTxvTu3dvcfffdDp2h33fffUaS8fHxMW3atDG9evUyVatWNRaLxTzzzDMu32b7WreMz2w6Y3L2/Ljb2rVrbbdtz9ghube3t4mJicl2Z+jW7haCg4NNs2bNTJ8+fUyXLl1s04eEhDh0hr5mzRpbnziVKlUyvXr1Mm3atDE+Pj6me/fuJjIy0kgyf/31l910Bw4cMKGhoUaSiYyMNF27djV333238fPzM61atbL1P5ixPuv7MTw83LRu3dr07dvXdOrUyZQoUcJIMmXLljVHjx61W87TTz9tm6ZHjx5m4MCBZuDAgU47Er8emXUrYIwxCQkJpkKFCkb6p7+xu+++2/Tp08d07tzZVK9e3VgsFlOyZEm7aTJ2fXHHHXeY3r17m+joaGOxWMwDDzyQ6Wv2Wq9lY67dhULG/WKJEiXMfffdZ1q1amVCQkJMrVq1bPuXgtaFQmacvdavXLlibrvtNiP901n3vffea3r06GHKly9vvL29zejRo7O8dXqjRo3MHXfcYfz9/U2HDh1Mjx49bB1GlyhRwqG7Gut+IjIy0nTp0sV4e3ub1q1bm169etn6UQwICHDoJuHf6tWrZ+sKILO+udwpJ9vWmH/6W2vZsqVtP92wYUPTo0cP0717d9OwYUPj4+NjJDn02ZXxdd+oUSPTrVs3U6NGDWOxWMy4ceMy3dde632enW4OMu6TypYta7p27Wo6depkQkJCTOnSpW3dIP379V3Qu1Cw9h1bsWJF07FjR9O3b1/Tpk0b4+fnZ6R/unu6cuWKMeafLoEsFouRZGrVqmV69eplWrRoYby9vU2LFi2c7peN+affNOvruGjRoiYmJsZ06dIlXzpDd2V9jfm/z5VChQqZZs2amZiYGBMVFWW8vb3NmDFjstwPZLYPtbK+lp988kljsVhsnZPXqlXLtszFixc7TJed/biz/a21uwpvb2/be65Hjx62/YbFYjH//e9/7eZz5coVW7+WXl5epl69eqZr166mZ8+eJjo62gQEBBhJDh2if/zxx7bO0GvVqmX7vmaxWMzw4cMLXBcKBacS5KlTp06ZwYMHm6ioKOPr62vKlClj7r//frNv3z6nO+/rCXnGGLNs2TLbGycoKMg0btzYrFixwqxbt872webK/Jyx9s3173kVdElJSWbKlCmmYcOGJigoyPj6+pry5cubTp06mYULF9rGu3z5snn55ZdNrVq1jL+/vylatKhp06aN+frrr3PUl9KNHvKMMebXX381MTExpmjRosbX19dUq1bNTJ482Vy5ciXbIW///v1mwoQJpmXLliYyMtIUKVLEhIWFmdq1a5sxY8Y4BCirnTt3mi5dupiiRYuaIkWKmOrVq5uXX37ZpKamGh8fH+Pl5WUuXrzoMN2uXbtMTEyMCQsLM76+vqZKlSrmhRdeMJcvX3Za3/bt282YMWNM48aNTdmyZY2Pj48pXry4ue2228ykSZOcBreLFy+aUaNGmUqVKtm+WF7rwzMnsgp5xvzzpXfq1KmmUaNGJjQ01Hh7e5vSpUubhg0bmpEjR5pNmzY5TLNixQpz1113mdDQUBMYGGgaNGhg3nrrLZOenp6rIc8YY/7880/Tr18/U6JECePj42MqVqxoRo4caZKSkgpsP3mZySyIJCUlmbFjx5oqVaqYIkWKmBIlSpjOnTubrVu3XrN/rKZNm5oLFy6YkSNHmooVKxofHx9TsmRJExsb67Q/voz7iStXrpgXX3zRVK1a1fj6+pqiRYuarl27Ou1j7N+s4TOz/lbdLafb1hhj0tLSzIIFC0z79u1NyZIljbe3tylWrJipWbOmGTBggFm+fLnT/jXnzZtn6tevb4oUKWKCg4NNixYtzDfffJPlvvZa7/PsBrGDBw+avn37msjISNvnz6OPPmpOnDiR6eu7oIe8zz77zDz22GOmXr16pnjx4sbHx8dERESYZs2amXnz5jk8B+vWrTMtW7Y04eHhxt/f39SsWdO8+OKLJjU1Ncvn+3//+58ZMmSIiYiIsC3j0UcfNadOnbrm/jE/1zc9Pd1Mnz7dVKtWzfj4+JiiRYuajh07mp9//jlb+4GsZHz/vP3226Zu3brGz8/PBAcHm7Zt29r1pZlRTkNeYmKiefXVV02XLl3MrbfeagIDA01AQICpXLmy6devn9m6dWum8/viiy9MTEyMKVu2rPH29jahoaGmWrVqplevXmbBggUmOTnZYZr169ebe+65xwQHBxt/f39Tr149M2vWLId1LwgsxhTg2wXB4z333HMaP368hgwZkuVpKdnRuHFjbdy4UQsWLFDv3r3dVCHgmnXr1qlp06aqVatWvl+TAbjD2rVr1bx5czVt2jTTvq2cOXTokCpWrKjy5cvn+KYEaWlpioqK0uHDh7Vp0yY1atQoR/MBkDesd5cmXuQ/rslDrtu3b5/TzotXrlypyZMny2KxXHcnkl9++aU2btyoyMjIm7JDZOStU6dOOb12NSEhwXZ3zgEDBuR1WYDHeffdd3X48GE1atSIgAcALih4Vy/D43z00UeaNGmS6tWrp3LlyunKlSvas2eP7SLhCRMm2Doxd8Xp06c1evRonT17Vl988YUkaerUqbY7jgG55bffflPz5s1VvXp13XLLLfLz89PBgwe1bds2paenq3Xr1rauDgC4Zs+ePXr55Zd14sQJffXVV/Ly8tK0adPyuywAuKEQ8pDr2rZtq3379unHH3/U7t27denSJRUrVkwdO3bU4MGDbV0JuCopKUmzZ89W4cKFdcstt2jEiBHq2bOnm6sHHFWuXFmPP/64vv/+e23cuNHW791dd92lPn366OGHHy6QdwAEbgTHjx/X7Nmz5ePjoxo1amjChAm666678rssALihcE0eAAAAAHgQrskDAAAAAA9CyAMAAAAAD0LIAwAAAAAPQsgDAAAAAA9CyAMAAAAAD0LIAwCgAJowYYLq1q2b32UAAG5AhDwAAP6/2NhYWSwWh7+c9ueZXRaLRStWrLBre/rpp7VmzZpcXS4AwDPRWy8AABm0bdtWc+bMsWvz9fXN8zoCAwMVGBiY58sFANz4OJIHAEAGvr6+KlWqlN1fWFiYpH+OuM2aNUsdOnSQv7+/qlWrph9++EH79+9Xs2bNFBAQoLvuukt//PGH3TzffvttRUVFycfHR1WqVNEHH3xgG1ahQgVJUpcuXWSxWGyP/326Znp6up577jlFRETI19dXdevW1VdffWUbfujQIVksFi1btkzNmzeXv7+/6tSpox9++CF3NhQAoMAi5AEA4ILnn39e/fr1044dO1S1alX16dNHjzzyiOLi4rR161YZY/TEE0/Yxl++fLmGDRumESNGKCEhQY888ogGDBig7777TpK0ZcsWSdKcOXN0/Phx2+N/e+211zR9+nRNmzZNv/zyi+655x516tRJ+/btsxvvmWee0dNPP60dO3aocuXK6t27t65evZpLWwMAUBAR8gAAyOCzzz6znSpp/Zs0aZJt+IABA9SjRw9VrlxZo0eP1qFDh9S3b1/dc889qlatmoYNG6a1a9faxp82bZpiY2M1ePBgVa5cWU899ZRiYmI0bdo0SVLx4sUlSaGhoSpVqpTt8b9NmzZNo0ePVq9evVSlShVNmTJFdevW1auvvmo33tNPP617771XlStX1sSJE3X48GHt37/fvRsJAFCgEfIAAMigefPm2rFjh93fo48+ahteu3Zt2/8lS5aUJNWqVcuu7dKlS0pMTJQk7d69W9HR0XbLiI6O1u7du7NdU2Jioo4dO5at+WSsr3Tp0pKkkydPZntZAIAbHzdeAQAgg4CAAFWqVCnT4d7e3rb/LRZLpm3p6em5VGHWClItAID8wZE8AAByUbVq1bRx40a7to0bN6p69eq2x97e3kpLS8t0HsHBwSpTpsw15wMAgMSRPAAA7KSmpurEiRN2bYULF1Z4eHiO5jdy5Ej16NFD9erVU6tWrbRq1SotW7ZM8fHxtnEqVKigNWvWKDo6Wr6+vra7ef57PuPHj1dUVJTq1q2rOXPmaMeOHfroo49yVBcAwHMR8gAAyOCrr76yXctmVaVKFf3+++85ml/nzp312muvadq0aRo2bJgqVqyoOXPmqFmzZrZxpk+frqeeekrvvfeeypYtq0OHDjnMZ+jQoTp//rxGjBihkydPqnr16lq5cqVuvfXWHNUFAPBcFmOMye8iAAAAAADuwTV5AAAAAOBBCHkAAAAA4EEIeQAAAADgQQh5AAAAAOBBCHkAAAAA4EEIeQAAAADgQQh5AAAAAOBBCHkAAAAA4EEIeQAAAADgQQh5AAAAAOBBCHkAAAAA4EH+H71paQRRz2DkAAAAAElFTkSuQmCC"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot emotions\n",
        "plt.figure(figsize=(35,4))\n",
        "plt.subplot(1,3,1)\n",
        "#np.unique returns ordered list of unique elements and count of each element\n",
        "emotion_list, count = np.unique(emotions, return_counts=True)\n",
        "plt.bar(x=range(8), height=count)\n",
        "plt.xticks(ticks=range(8), labels = [emotion for emotion in emotion_list],fontsize=10)\n",
        "plt.xlabel('Emotion')\n",
        "plt.tick_params(labelsize=16)\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged dataset"
      ],
      "metadata": {
        "id": "TmIPLqxPV22a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot emotions\n",
        "plt.figure(figsize=(35,4))\n",
        "plt.subplot(1,3,1)\n",
        "#np.unique returns ordered list of unique elements and count of each element\n",
        "emotion_list, count = np.unique(emotions_Merged, return_counts=True)\n",
        "plt.bar(x=range(8), height=count)\n",
        "plt.xticks(ticks=range(8), labels = [emotion for emotion in emotion_list],fontsize=10)\n",
        "plt.xlabel('Emotion')\n",
        "plt.tick_params(labelsize=16)\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3Ur20DJV50_",
        "outputId": "e80feb26-f6ee-4cdf-c196-4543592f4e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x400 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Own Audio"
      ],
      "metadata": {
        "id": "XzrQUG6kWNDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot emotions\n",
        "plt.figure(figsize=(35,4))\n",
        "plt.subplot(1,3,1)\n",
        "#np.unique returns ordered list of unique elements and count of each element\n",
        "emotion_list, count = np.unique(emotions_Own, return_counts=True)\n",
        "plt.bar(x=range(8), height=count)\n",
        "plt.xticks(ticks=range(8), labels = [emotion for emotion in emotion_list],fontsize=10)\n",
        "plt.xlabel('Emotion')\n",
        "plt.tick_params(labelsize=16)\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KrPzXcYbWPt9",
        "outputId": "7c52a905-5e8f-4dea-fc25-1d8dd76bbd07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x400 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_wKC8WL9hV"
      },
      "source": [
        "**Great, the classes appear to be balanced. That makes the task easier.** All emotions _except_ the neutral class have a \"strong\" intensity so there are half as many neutral samples. That might have an impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhtlYshOL9hV"
      },
      "source": [
        "### Feature Scaling\n",
        "To properly train most machine learning models on _most_ datasets, we first need to scale our features. **This is crucial for models which compute distances between data, and especially critical for DNNs**: If there is a difference in the variance of features simply because of their possible range of values, then a model will learn that the features with the greatest variance are the most important. However, **differences in the variance of unscaled features belonging to different and unknown distributions is an inappropriate measure of importance.** Let's check our features' properties:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "_IUm1DLwL9hW",
        "outputId": "a71101ad-2b11-490e-e269-69743b35a6ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 Chromagram features:           min = 0.310,     max = 1.000,     mean = 0.667,     deviation = 0.087\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 149.208,     mean = 0.187,     deviation = 1.597\n",
            "\n",
            "40 MFCC features:                 min = -1131.371,    max = 115.126,    mean = -14.673,    deviation = 98.875\n"
          ]
        }
      ],
      "source": [
        "# We would usually use df.describe(), but it provides a bit of a mess of information we don't need at the moment.\n",
        "def print_features(df):\n",
        "    # Check chromagram feature values\n",
        "    features_df_chromagram = df.loc[:,:11]\n",
        "    chroma_min = features_df_chromagram.min().min()\n",
        "    chroma_max = features_df_chromagram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    chroma_mean = features_df_chromagram.stack().mean()\n",
        "    chroma_stdev = features_df_chromagram.stack().std()\n",
        "    print(f'12 Chromagram features:       \\\n",
        "    min = {chroma_min:.3f}, \\\n",
        "    max = {chroma_max:.3f}, \\\n",
        "    mean = {chroma_mean:.3f}, \\\n",
        "    deviation = {chroma_stdev:.3f}')\n",
        "\n",
        "    # Check mel spectrogram feature values\n",
        "    features_df_melspectrogram = df.loc[:,12:139]\n",
        "    mel_min = features_df_melspectrogram.min().min()\n",
        "    mel_max = features_df_melspectrogram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mel_mean = features_df_melspectrogram.stack().mean()\n",
        "    mel_stdev = features_df_melspectrogram.stack().std()\n",
        "    print(f'\\n128 Mel Spectrogram features: \\\n",
        "    min = {mel_min:.3f}, \\\n",
        "    max = {mel_max:.3f}, \\\n",
        "    mean = {mel_mean:.3f}, \\\n",
        "    deviation = {mel_stdev:.3f}')\n",
        "\n",
        "    # Check MFCC feature values\n",
        "    features_df_mfcc = df.loc[:,140:179]\n",
        "    mfcc_min = features_df_mfcc.min().min()\n",
        "    mfcc_max = features_df_mfcc.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mfcc_mean = features_df_mfcc.stack().mean()\n",
        "    mfcc_stdev = features_df_mfcc.stack().std()\n",
        "    print(f'\\n40 MFCC features:             \\\n",
        "    min = {mfcc_min:.3f},\\\n",
        "    max = {mfcc_max:.3f},\\\n",
        "    mean = {mfcc_mean:.3f},\\\n",
        "    deviation = {mfcc_stdev:.3f}')\n",
        "\n",
        "print_features(features_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged"
      ],
      "metadata": {
        "id": "FqrHRHS0YI5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We would usually use df.describe(), but it provides a bit of a mess of information we don't need at the moment.\n",
        "def print_features(df):\n",
        "    # Check chromagram feature values\n",
        "    featureMerged_df_chromagram = df.loc[:,:11]\n",
        "    chroma_min = featureMerged_df_chromagram.min().min()\n",
        "    chroma_max = featureMerged_df_chromagram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    chroma_mean = featureMerged_df_chromagram.stack().mean()\n",
        "    chroma_stdev = featureMerged_df_chromagram.stack().std()\n",
        "    print(f'12 Chromagram features:       \\\n",
        "    min = {chroma_min:.3f}, \\\n",
        "    max = {chroma_max:.3f}, \\\n",
        "    mean = {chroma_mean:.3f}, \\\n",
        "    deviation = {chroma_stdev:.3f}')\n",
        "\n",
        "    # Check mel spectrogram feature values\n",
        "    featureMerged_df_melspectrogram = df.loc[:,12:139]\n",
        "    mel_min = featureMerged_df_melspectrogram.min().min()\n",
        "    mel_max = featureMerged_df_melspectrogram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mel_mean = featureMerged_df_melspectrogram.stack().mean()\n",
        "    mel_stdev = featureMerged_df_melspectrogram.stack().std()\n",
        "    print(f'\\n128 Mel Spectrogram features: \\\n",
        "    min = {mel_min:.3f}, \\\n",
        "    max = {mel_max:.3f}, \\\n",
        "    mean = {mel_mean:.3f}, \\\n",
        "    deviation = {mel_stdev:.3f}')\n",
        "\n",
        "    # Check MFCC feature values\n",
        "    featureMerged_df_mfcc = df.loc[:,140:179]\n",
        "    mfcc_min = featureMerged_df_mfcc.min().min()\n",
        "    mfcc_max = featureMerged_df_mfcc.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mfcc_mean = featureMerged_df_mfcc.stack().mean()\n",
        "    mfcc_stdev = featureMerged_df_mfcc.stack().std()\n",
        "    print(f'\\n40 MFCC features:             \\\n",
        "    min = {mfcc_min:.3f},\\\n",
        "    max = {mfcc_max:.3f},\\\n",
        "    mean = {mfcc_mean:.3f},\\\n",
        "    deviation = {mfcc_stdev:.3f}')\n",
        "\n",
        "print_features(featureMerged_df)"
      ],
      "metadata": {
        "id": "zt4owjKkYLVK",
        "outputId": "7b639eb1-1ead-410e-cb3b-95e030a72be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 Chromagram features:           min = 0.310,     max = 1.000,     mean = 0.669,     deviation = 0.090\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 149.208,     mean = 0.186,     deviation = 1.593\n",
            "\n",
            "40 MFCC features:                 min = -1131.371,    max = 115.126,    mean = -14.749,    deviation = 99.476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Own"
      ],
      "metadata": {
        "id": "t5Uj6p3bYiga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We would usually use df.describe(), but it provides a bit of a mess of information we don't need at the moment.\n",
        "def print_features(df):\n",
        "    # Check chromagram feature values\n",
        "    featureOwn_df_chromagram = df.loc[:,:11]\n",
        "    chroma_min = featureOwn_df_chromagram.min().min()\n",
        "    chroma_max = featureOwn_df_chromagram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    chroma_mean = featureOwn_df_chromagram.stack().mean()\n",
        "    chroma_stdev = featureOwn_df_chromagram.stack().std()\n",
        "    print(f'12 Chromagram features:       \\\n",
        "    min = {chroma_min:.3f}, \\\n",
        "    max = {chroma_max:.3f}, \\\n",
        "    mean = {chroma_mean:.3f}, \\\n",
        "    deviation = {chroma_stdev:.3f}')\n",
        "\n",
        "    # Check mel spectrogram feature values\n",
        "    featureOwn_df_melspectrogram = df.loc[:,12:139]\n",
        "    mel_min = featureOwn_df_melspectrogram.min().min()\n",
        "    mel_max = featureOwn_df_melspectrogram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mel_mean = featureOwn_df_melspectrogram.stack().mean()\n",
        "    mel_stdev = featureOwn_df_melspectrogram.stack().std()\n",
        "    print(f'\\n128 Mel Spectrogram features: \\\n",
        "    min = {mel_min:.3f}, \\\n",
        "    max = {mel_max:.3f}, \\\n",
        "    mean = {mel_mean:.3f}, \\\n",
        "    deviation = {mel_stdev:.3f}')\n",
        "\n",
        "    # Check MFCC feature values\n",
        "    featureOwn_df_mfcc = df.loc[:,140:179]\n",
        "    mfcc_min = featureOwn_df_mfcc.min().min()\n",
        "    mfcc_max = featureOwn_df_mfcc.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mfcc_mean = featureOwn_df_mfcc.stack().mean()\n",
        "    mfcc_stdev = featureOwn_df_mfcc.stack().std()\n",
        "    print(f'\\n40 MFCC features:             \\\n",
        "    min = {mfcc_min:.3f},\\\n",
        "    max = {mfcc_max:.3f},\\\n",
        "    mean = {mfcc_mean:.3f},\\\n",
        "    deviation = {mfcc_stdev:.3f}')\n",
        "\n",
        "print_features(featureOwn_df)"
      ],
      "metadata": {
        "id": "K4fqi5wwYkbd",
        "outputId": "95e990cd-5b44-4e8b-d3d3-f71447f111ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 Chromagram features:           min = 0.976,     max = 1.000,     mean = 0.990,     deviation = 0.008\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 0.000,     mean = 0.000,     deviation = 0.000\n",
            "\n",
            "40 MFCC features:                 min = -1131.371,    max = 0.000,    mean = -28.284,    deviation = 176.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFgQlYSlL9hW"
      },
      "source": [
        "**There's an obvious imbalance in the variance our features; Our features indeed belong to very different distributions:** our MFC coefficients' deviation is greater than the other features by orders of magnitude. That does not mean MFC coefficients are the most important feature, but rather it is a property of the way they are computed.  We will certainly need to scale this feature set.\n",
        "\n",
        "We have the choice of sklearn's StandardScaler and MinMaxScaler. Standard scaling subtracts the mean of each feature and divides it by the standard deviation of that feature, producing features with mean at zero and unit variance - that is, a variance and standard deviation of 1. Min-Max scaling transforms each feature to be within a bounded interval that we specify.\n",
        "\n",
        "In practice, **MinMax scaling is especially useful when we know our features should be in a bounded interval**, such as pixel values in [0,255], while **standard scaling is perhaps more practical for features with unknown distributions** because centering the features at zero-mean with a standard deviation of 1 means extreme values will have less of an impact on the model's learned weights, i.e. the model is less sensitive to outliers.\n",
        "\n",
        "We'll create MinMax scaled features as well so we can give them a try later on to confirm that standard scaling is better in the absence of knowledge on the appropriate distribution for a dataset's features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "_BCAYVEUL9hW",
        "outputId": "48022b5d-d5f9-4126-b34e-cf01566f4fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with dim 3. MinMaxScaler expected <= 2.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[112], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Only My Audio\u001b[39;00m\n\u001b[0;32m     23\u001b[0m featureOwn_scaled \u001b[38;5;241m=\u001b[39m featureOwn\n\u001b[1;32m---> 24\u001b[0m featureOwn_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureOwn_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# keep our unscaled features just in case we need to process them alternatively\u001b[39;00m\n\u001b[0;32m     27\u001b[0m featureOwn_minmax \u001b[38;5;241m=\u001b[39m features\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1065\u001b[0m         array,\n\u001b[0;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1069\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. MinMaxScaler expected <= 2."
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "features_scaled = features\n",
        "features_scaled = scaler.fit_transform(features_scaled)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "features_minmax = features\n",
        "features_minmax = scaler.fit_transform(features_minmax)\n",
        "\n",
        "# Merged Dataset\n",
        "featureMerged_scaled = featureMerged\n",
        "featureMerged_scaled = scaler.fit_transform(featureMerged_scaled)\n",
        "\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "featureMerged_minmax = features\n",
        "featureMerged_minmax = scaler.fit_transform(featureMerged_minmax)\n",
        "\n",
        "# Only My Audio\n",
        "featureOwn_scaled = featureOwn\n",
        "featureOwn_scaled = scaler.fit_transform(featureOwn_scaled)\n",
        "\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "featureOwn_minmax = features\n",
        "featureOwn_minmax = scaler.fit_transform(featureOwn_minmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ATx5oNL9hX"
      },
      "source": [
        "Make sure our features are properly scaled:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "mlRuHQkKL9hX",
        "outputId": "39d64fb3-6ab1-42cc-f809-6ce4e91b0b2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mStandard Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = -3.897,     max = 4.369,     mean = -0.000,     deviation = 1.000\n",
            "\n",
            "128 Mel Spectrogram features:     min = -0.474,     max = 36.543,     mean = 0.000,     deviation = 1.000\n",
            "\n",
            "40 MFCC features:                 min = -4.804,    max = 6.240,    mean = 0.000,    deviation = 1.000\n",
            "\n",
            "\n",
            "\u001b[1mMinMax Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = 0.000,     max = 1.000,     mean = 0.472,     deviation = 0.145\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 1.000,     mean = 0.015,     deviation = 0.061\n",
            "\n",
            "40 MFCC features:                 min = 0.000,    max = 1.000,    mean = 0.413,    deviation = 0.169\n"
          ]
        }
      ],
      "source": [
        "print('\\033[1m'+'Standard Scaling:\\n'+'\\033[0m')\n",
        "features_scaled_df = pd.DataFrame(features_scaled)\n",
        "print_features(features_scaled_df)\n",
        "\n",
        "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
        "features_minmax_df = pd.DataFrame(features_minmax)\n",
        "print_features(features_minmax_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged"
      ],
      "metadata": {
        "id": "JOl7MSGgY049"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1m'+'Standard Scaling:\\n'+'\\033[0m')\n",
        "featureMerged_scaled_df = pd.DataFrame(featureMerged_scaled)\n",
        "print_features(featureMerged_scaled_df)\n",
        "\n",
        "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
        "featureMerged_minmax_df = pd.DataFrame(featureMerged_minmax)\n",
        "print_features(featureMerged_minmax_df)"
      ],
      "metadata": {
        "id": "K6rBUPXLY4Tl",
        "outputId": "c97d5e98-c6ab-4fed-8146-3d753c87982f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mStandard Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = 0.000,     max = 1.000,     mean = 0.473,     deviation = 0.149\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 1.000,     mean = 0.014,     deviation = 0.060\n",
            "\n",
            "40 MFCC features:                 min = 0.000,    max = 1.000,    mean = 0.412,    deviation = 0.169\n",
            "\n",
            "\n",
            "\u001b[1mMinMax Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = 0.000,     max = 1.000,     mean = 0.472,     deviation = 0.145\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 1.000,     mean = 0.015,     deviation = 0.061\n",
            "\n",
            "40 MFCC features:                 min = 0.000,    max = 1.000,    mean = 0.413,    deviation = 0.169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Own"
      ],
      "metadata": {
        "id": "wg62vMoFZZgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1m'+'Standard Scaling:\\n'+'\\033[0m')\n",
        "featureOwn_scaled_df = pd.DataFrame(featureOwn_scaled)\n",
        "print_features(featureOwn_scaled_df)\n",
        "\n",
        "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
        "featureOwn_minmax_df = pd.DataFrame(featureOwn_minmax)\n",
        "print_features(featureOwn_minmax_df)"
      ],
      "metadata": {
        "id": "Gd8xWbmNZc57",
        "outputId": "c1569069-d47a-43dc-f5a9-3b695e324af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mStandard Scaling:\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must pass 2-d input. shape=(8, 1440, 180)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[115], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard Scaling:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m featureOwn_scaled_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureOwn_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m print_features(featureOwn_scaled_df)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinMax Scaling:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:314\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    308\u001b[0m     _copy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    309\u001b[0m         copy_on_sanitize\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, dtype))\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, copy\u001b[38;5;241m=\u001b[39m_copy)\n\u001b[1;32m--> 314\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
            "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(8, 1440, 180)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZfzIh7DL9hX"
      },
      "source": [
        "Perfect. Zero mean and unit variance for standard scaling and in the range [0,1] for MinMax scaling - a default when we don't specify values. We can now move on to building predictive models for these features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5tXewLEL9hX"
      },
      "source": [
        "## Classical Machine Learning Models\n",
        "\n",
        "\n",
        "Classical machine learning models encompass a broad range of algorithms that have been foundational to the field's development and are still widely used for various predictive tasks. These models can be broadly categorized into supervised and unsupervised learning methods, each suited for different kinds of data and objectives.\n",
        "\n",
        "We will be looking into few popular Machine Learning Algorithms such as Support Vector Machine(SVM), K-Nearest Neighbors and Random Forest Classifier. There are many other classical models with their own strengths and weaknesses, and the choice of model depends on the specific requirements of the task, including the nature of the data, the complexity of the problem, and the computational efficiency required. Despite the rise of deep learning, classical machine learning models remain vital tools in a data scientist's arsenal due to their efficiency, interpretability, and strong performance in many scenarios.\n",
        "\n",
        "The use of classic machine learning method is due to the small size of our dataset; Some of the most robust models such as Support vector (machine) classifiers **(SVC) and k-Nearest-Neighbour classifiers (kNN) are particularly suited to smaller datasets and fall apart with huge datasets.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwU-jXSGL9hY"
      },
      "source": [
        "### Training: The 80/20 Split and Validation\n",
        "In order to compare models, we'll have to evaluate their performance. The simplest method to do so is to train a model on a portion of our dataset and test it on the remainder. We'll use sklearn's train_test_split to create a standard 80/20 train/test split. The model is fit on 80% of\n",
        "the data and tested for performance against 20% of the data, which it has never seen in training - also called the hold-out set.\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/Capture2.PNG?raw=true\" width=\"800\">\n",
        "\n",
        "More accurately, the proper modality for training and scoring a model is to\n",
        "1. Fit/train our model on a _training_ set,\n",
        "2. Evaluate the model on a _validation_ set to tune the hyperparameters for better performance,\n",
        "3. Finally score our model's true performance - its **generalizability** - against a _test_ set, aka the hold-out set.\n",
        "4. Repeat from 2. **Do not tune the model to score well on the test set**. Only evaluate on test-set once.\n",
        "\n",
        "Different set ratios are used in this approach - a usual example is 60/20/20 train/validation/test.For simplicity, we're going to start with an 80/20 train/test split. The model will be trained on all the training data, and we will check its performance on the test data. We'll skip validation for now.\n",
        "\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-ClassicML/blob/main/images/traintestsplit.PNG?raw=true\" width=\"800\">\n",
        "\n",
        "Define unscaled and scaled training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8jGN4ROVL9hY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "############# Unscaled test/train set #############\n",
        "X_train, X_test, y_train, y_test =train_test_split(\n",
        "    features,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "############ Standard Scaled test/train set ###########\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "X_train_scaled, X_test_scaled, _, _ = train_test_split(\n",
        "    features_scaled,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "############# MinMax Scaled test/train set ###############\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "X_train_minmax, X_test_minmax, _, _ = train_test_split(\n",
        "    features_minmax,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merged"
      ],
      "metadata": {
        "id": "9P-AxC7Bd3l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############# Unscaled test/train set #############\n",
        "merged_X_train, merged_X_test, merged_y_train, merged_y_test =train_test_split(\n",
        "    featureMerged,\n",
        "    emotionsMerged,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "############ Standard Scaled test/train set ###########\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "merged_X_train_scaled, merged_X_test_scaled, _, _ = train_test_split(\n",
        "    featureMerged_scaled,\n",
        "    emotionsMerged,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "############# MinMax Scaled test/train set ###############\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "merged_X_train_minmax, merged_X_test_minmax, _, _ = train_test_split(\n",
        "    featureMerged_minmax,\n",
        "    emotionsMerged,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "4uZx2esvd6l8",
        "outputId": "75ca9dec-7e7a-4a12-fe47-8818d3c3636d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1440, 1447]",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[68], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m merged_X_train_scaled, merged_X_test_scaled, _, _ \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     12\u001b[0m     featureMerged_scaled,\n\u001b[0;32m     13\u001b[0m     emotionsMerged,\n\u001b[0;32m     14\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     15\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m############# MinMax Scaled test/train set ###############\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# The labels/classes (y_train, y_test) never change, keep old values\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m merged_X_train_minmax, merged_X_test_minmax, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatureMerged_minmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43memotionsMerged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2782\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2786\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2787\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1440, 1447]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Mh0RrEL9hY"
      },
      "source": [
        "### Comparing Models\n",
        "We'll try each off-the-shelf machine learning model from sklearn and pick a few to explore, since these models will train near instantly on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "scrolled": true,
        "id": "iLPeyR7vL9he",
        "outputId": "1ab84e92-e890-4155-9290-696897a13f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Classifier Accuracy Score\n",
              "4         RandomForestClassifier         55.56%\n",
              "0           KNeighborsClassifier         55.21%\n",
              "2                 SVC RBF kernel         51.74%\n",
              "1                            SVC         50.35%\n",
              "3         DecisionTreeClassifier         36.11%\n",
              "6                     GaussianNB         30.21%\n",
              "5             AdaBoostClassifier         25.69%\n",
              "7  QuadraticDiscriminantAnalysis         20.49%"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>55.56%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>55.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC RBF kernel</td>\n",
              "      <td>51.74%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC</td>\n",
              "      <td>50.35%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>36.11%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>30.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>25.69%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>20.49%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classification_models = [\n",
        "    KNeighborsClassifier(),#(3),\n",
        "    SVC(kernel='linear'),#, C=0.025),\n",
        "    SVC(kernel='rbf'),\n",
        "    DecisionTreeClassifier(),#max_depth=5),\n",
        "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "scores = []\n",
        "for model in classification_models:\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    score = model.score(X_test_scaled, y_test)\n",
        "    model_name = type(model).__name__\n",
        "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
        "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
        "# Make it pretty\n",
        "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
        "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrD98CpPL9he"
      },
      "source": [
        "Let's pick the top three - Random Forests, SVC, and kNN - and take a closer look at each of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBNoEolL9hf"
      },
      "source": [
        "### The Support Vector Machine Classifier\n",
        "\n",
        "We'll go in chronological order. First is the support vector machine classifier (SVC) - a model from the 60s. SVMs are models quick to train for this task and best suited to small datasets due to its quadratic time complexity w.r.t. size of the training dataset (# of training samples). This is also the reason it breaks down with larger datasets since it becomes very expensive to train.\n",
        "\n",
        "The idea behind SVMs on which the SVC model is based is to find a separating hyperplane - a subspace with dimension one less than that of the feature space - for points in our feature space; i.e. for a 3D space, a hyperplane is a regular plane, in 2D, a line. This idea extends to n dimensions. If points are separable by a hyperplane, they are said to be linearly separable. **Since there are infinite possible separating hyperplanes for any linearly separable feature space, an SVM computes which points are closest to each such hyperplane and uses them to construct a _support vector_. The SVM picks the hyperplane which maximizes the distance - _margin_ - to each support vector.** In this way, we maximize the separating ability of the chosen hyperplane.\n",
        "\n",
        "The core of SVMs is the kernel. We could map all new points from our input space, where they were not separable by a hyperplane, to a higher dimension in which we have found a hyperplane to separate the points in that space. However, that would be extremely computationally expensive for data that needs to be mapped to much higher dimensions. Instead, we **compute the hyperplane in the higher dimension on our training data and map the hyperplane back to the lower-dimension input space to use for classifying our data. This is the _kernel trick_, whereby the kernel (function) enables us to compute distances to new points in the input space without transforming each to the higher dimensional space - drastically reducing the computational complexity of the SVM.**\n",
        "\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/kernel1.png?raw=true\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-VTE6HjL9hf"
      },
      "source": [
        "A linear kernel should always be tested because **a linear kernel is much faster to train than a non-linear kernel**; however, properly tuned, a non-linear kernel often provides the best possible predictive performance. **RBF (radial basis function) is a good default to use for a non-linear kernel** and often is the best non-linear kernel because it usually provides a higher accuracy compared to other non-linear kernels at the cost of higher computational complexity. We can afford to try the RBF kernel because our dataset is small.\n",
        "\n",
        "If you want to explore further please have a look at [this article](https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ruBbt50ML9hf",
        "outputId": "017cec5b-eaf5-4941-c77c-7c0f9f326b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Model's accuracy on training set is 99.74%\n",
            "SVC Model's accuracy on test set is 47.22%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(\n",
        "    C=10,  #higher the value tighter the margin\n",
        "    gamma='auto',\n",
        "    kernel='rbf',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'SVC Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'SVC Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIm1a-tiL9hg"
      },
      "source": [
        "Not bad at all for the relatively simple SVC model. **Hyperparameter ð¶ regulates the margin.** It might do well to optimize the SVC model further if we don't find a better one. As it stands, we are looking for considerably higher performance in this task.\n",
        "\n",
        "Check out [this link](https://towardsdatascience.com/visualizing-the-effect-of-hyperparameters-on-support-vector-machines-b9eef6f7357b) for visual representation of affect of changes in C and gamma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72LJRfCL9hg"
      },
      "source": [
        "### k Nearest Neighbours\n",
        "\n",
        "k Nearest Neighbours (kNN) is next in line, a tried-and-true machine learning method from the 70s. kNN makes a lot of intuitive sense: imagine plotting points on a graph and drawing gates around points that look like they belong to the same group. That's what it is - we **plot our training samples' features and compare a test sample's features' distance to all those points; then just take the _k_ closest points to the test sample and pick the most frequent label/class.** That's it.\n",
        "\n",
        "kNN is a great starting point for multiclass problems with small datasets, although on large dadtasets less reliable and extremely memory hungry (it stores all training sample points). kNN is also useful in that it makes **no assumptions about the underlying distribution of the data set - so kNNs work well for both linear and non-linear data.** In the 2D example:\n",
        "\n",
        "<img src=\"https://github.com/IAT-ExploringAI-2024/Week3-ClassicML/blob/main/images/knn.png?raw=true\" width=400 height=400 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qaeCneMiL9hg",
        "outputId": "771778b3-67df-4f07-873d-70f9694acdcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default kNN Model's accuracy on training set is 66.23%\n",
            "Default kNN Model's accuracy on test set is 46.18%\n",
            "\n",
            "kNN Model's accuracy on training set is 99.83%\n",
            "kNN Model's accuracy on test set is 50.69%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "####### Default kNN  ########\n",
        "model = KNeighborsClassifier(\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Default kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "##### (hastily) tuned kNN ######\n",
        "model = KNeighborsClassifier(\n",
        "    n_neighbors = 5, ## the \"K\" in K nearest neighbours\n",
        "    weights = 'distance',\n",
        "    algorithm = 'brute',\n",
        "    n_jobs=4\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxVEKUyiL9hh"
      },
      "source": [
        "**The brute-force algorithm computes distances between all pairs of points in the training set; works especially well for small datasets** but wildly inefficient w.r.t. increasing samples and feature space dimension. Not bad for 2 minutes of work, but still not suitable for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvQ3av4cL9hh"
      },
      "source": [
        "### Random Forests\n",
        "Finally, and before resorting to deep learning methods, let's try a Random Forest -  a model from the 21st century (2001). **We train many distinct decision trees which are essentially directed acyclic graphs (DAGs), somewhat similar to a flow chart. The collection of (decision) trees makes up our Random Forest.**\n",
        "\n",
        "At each node of the tree we have a function (a rule) that evaluates whether the features of samples input to that node belong to one class or another. Each branch of the tree (or, edge of the graph) defines one of two possible results from a node, and each leaf is one of two decisions made by its parent node. **Each tree in the forest evaluates a random subset of the training samples' features and has a rule at each level of the tree that classifies based on these random features - hence, _Random_ Forest. This random selection of features makes Random Forests robust to outliers**, as such features will have less of an impact in the scope of the entire forest, most of whose trees operate on the \"real\" features.\n",
        "\n",
        "**Random Forests are excellent models to use as a benchmark due to their low time complexity to train and because it is an ensemble method, their robustness to unknown distributions and outliers in the dataset,** meaning Random Forests require relatively little exploratory analysis in both the data and training the model to get an idea of their performance in a task.\n",
        "\n",
        "<img src=\"https://github.com/IliaZenkov/sklearn-audio-classification/blob/master/img/randomforest.png?raw=true\" width=500 height=500 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "j9BWmcV9L9hh",
        "outputId": "87dfc01a-b5da-4d8a-b8c2-e59e22d31e9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Random Forest Model's accuracy on training set is 100.00%\n",
            "Default Random Forest Model's accuracy on test set is 52.78%\n",
            "\n",
            "Random Forest Model's accuracy on training set is 100.00%\n",
            "Random Forest Model's accuracy on test set is 55.90%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "####### Default Random Forest ########\n",
        "model = RandomForestClassifier(\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Default Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "\n",
        "########## Tuned Random Forest #######\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators = 500,\n",
        "    criterion ='entropy',\n",
        "    warm_start = True,\n",
        "    max_features = 'sqrt',\n",
        "    oob_score = True, # more on this below\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9-k8KLL9hi"
      },
      "source": [
        "Not bad for zero effort put into the default model. **Random Forests make a good benchmark model**, especially when strapped for time.\n",
        "\n",
        "**_Max features_ defines size of random feature subset decided upon at each node; sqrt(#features) is a good default for classification.**\n",
        "\n",
        "**_Gini_ and _Entropy_ are functions computing quality of classified samples within each node; they almost always provide similar performance but Entropy is more suited to classification while Gini is better for continuous variables.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnhnxuGXL9hi"
      },
      "source": [
        "\n",
        "As wonderful as Random Forests are, it's clear that we're going to need to pull out bigger guns if we want to get appreciable performance on this dataset, perhaps even with good generalizability on test data. DNNs(Deep Neural Networks) are the next step-up in complexity from classical machine learning models, and we will start at the first rung on that ladder:Simple Perceptron in next lab!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (Speech Classifier)",
      "language": "python",
      "name": "pycharm-6a34225"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}